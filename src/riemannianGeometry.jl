#    Unit riemannianGeometry.jl, part of PosDefManifold Package for julia language
#    v 0.1.0 - last update 10th of April 2019
#
#    MIT License
#    Copyright (c) 2019, Marco Congedo, CNRS, Grenobe, France:
#    https://sites.google.com/site/marcocongedo/home
#
#    DESCRIPTION
#    This Unit implements Riemannian Geometry operations on the manifold
#    of Symmetric Positive Definite (SPD) or Hermitian matrices
#
#    CONTENT
#    1. Geodesic Equations
#    2. Distances
#    3. Inter-distance matrices, Laplacian and Spectral Embedding
#    4. Means (center of mass, barycenters, ...)
#    5. Tangent Space
#    6. Procrustes Problems

# -----------------------------------------------------------
# 1. Geodesic Equations
# -----------------------------------------------------------

"""
    geodesic(P::‚Ñç, Q::‚Ñç, a::Real, metric::Metric=Fisher)

  Move along the [geodesic](@ref) from point ``P`` to point ``Q``
  (two positive definite matrices) with *arclegth* ``0<=a<=1``,
 using the specified metric, of type [Metric::Enumerated type](@ref).
 By default de [Fisher](@ref) metric is adopted.

 For all metrics,
 - with ``a=0`` we stay at ``P``,
 - with ``a=1`` we move up to ``Q``,
 - with ``a=1/2`` we move to the mid-point of ``P`` and ``Q`` (mean).

 Using the Fisher metric argument `a` can be *any* real number, for instance:
 - with ``0<a<1`` we move toward ``Q`` (*attraction*),
 - with ``a>1`` we move over and beyond ``Q`` (*extrapolation*),
 - with ``a<0`` we move back away from Q (*repulsion*).

 Note that if ``Q=I``, the Fisher geodesic move is simply ``P^a``
 (no need to call this funtion then).

 For the [logdet zero](@ref) and [Jeffrey](@ref) metric no closed form expression
 for the geodesic is available (to the best of authors' knowledge),
 so in this case the geodesic is found as the weighted mean [`meanP(@ref)`].
 For the [Von Neumann](@ref) not even an expression for the mean is available,
 so in this case the geodesic is not provided and a *warning* is printed.

 ``P`` and ``Q`` must be flagged by julia as `Hermitian`.
 See [typecasting matrices](@ref).

 **Maths**

 For points ``P``, ``Q`` and arclength ``a``, letting ``b=1-a``,
 the geodesic equations for the supported metrics are:

| Metric   | geodesic equation |
|:----------:|:----------- |
|Euclidean| ``bP + aQ`` |
|invEuclidean| ``\\big(bP^{-1} + aQ^{-1}\\big)^{-1}``|
|ChoEuclidean| ``TT^*``, where ``T=bL_P + aL_Q``|
|logEuclidean| ``\\text{exp}\\big(b\\text{log}(P) + a\\text{log}(Q)\\big)``|
|logCholesky| ``TT^*``, where ``T=S_P+a(S_Q-S_P)+D_P\\hspace{2pt}\\text{exp}\\big(a(\\text{log}D_Q-\\text{log}D_P)\\big)``|
|Fisher | ``P^{1/2} \\big(P^{-1/2} Q P^{-1/2}\\big)^a P^{1/2}``|
|logdet0| uses weighted mean algorithm [`logdet0Mean`](@ref) |
|Jeffrey | uses weighted mean [`meanP`](@ref) |
|VonNeumann | N.A.|
|Wasserstein| ``b^2P+a^2Q +ab\\big[(PQ)^{1/2} +(QP)^{1/2}\\big]``|

  **legend:** ``L_X``, ``S_X`` and ``D_X``
   are the Cholesky lower triangle of ``X``, its strictly lower triangular part
   and diagonal part, respectively (hence, ``S_X+D_X=L_X``,  ``L_XL_X^*=X``).

 **See also**: [`meanP`](@ref)

 ## Examples
    using PosDefManifold
    P=randP(10);
    Q=randP(10);
    # Wasserstein mean
    M=geodesic(P, Q, 0.5, Wasserstein)
    # extrapolate suing the Fisher metric
    E=geodesic(P, Q, 2)

"""
function geodesic(P::‚Ñç, Q::‚Ñç, a::Real, metric::Metric=Fisher)
    if a ‚âà 0 return P end
    if a ‚âà 1 return Q end
    b = 1-a

    if      metric==Euclidean
    return  ‚Ñç(P*b + Q*a)

    elseif  metric==invEuclidean
    return  ‚Ñç( inv( ‚Ñç(inv(P)*b + inv(Q)*a) ) )

    elseif  metric==logEuclidean
    return  ‚Ñç( exp( ‚Ñç(log(P)*b + log(Q)*a) ) )

    elseif  metric==Fisher
            P¬Ω, P‚Åª¬Ω = pow(P, 0.5, -0.5)
    return  ‚Ñç( P¬Ω * ‚Ñç((P‚Åª¬Ω * Q * P‚Åª¬Ω)^a) * P¬Ω )

    elseif  metric in (logdet0, Jeffrey)
    return  meanP([P, Q], metric, w=[b, a], ‚úìw=false) #! 2

    elseif  metric==VonNeumann
            @warn("An expression for the geodesic is not available for the Von neumann metric")

    elseif  metric==ChoEuclidean
            L=choL(P)*b + choL(Q)*a
    return  ‚Ñç(L*L')

    elseif  metric==logCholesky
            LP=choL(P); LQ=choL(Q); slLP=tril(LP,-1)
            #L=slLP+a*(tril(LQ,-1)-slLP)+‚ã±(LP)*exp(a*(ùëìùë´(LQ, log)-ùëìùë´(LP, log)))
            L=slLP+(tril(LQ,-1)-slLP)*a
            for i in 1:size(P, 1) L[i, i]+=LP[i, i]*exp( (log(LQ[i, i])-log(LP[i, i]))*a ) end
    return  ‚Ñç(L*L')

    elseif  metric==Wasserstein
            if isreal(P) && isreal(Q)
                    return ‚Ñç( (b^2)*P + (a^2)*Q + (a*b)*real(‚àö(P*Q)+‚àö(Q*P)) )
            else    return ‚Ñç( (b^2)*P + (a^2)*Q + (a*b)*(‚àö(P*Q)+‚àö(Q*P)) )
            end

    else    @warn("in RiemannianGeometryP.geodesic function
                 (PosDefManifold Package): the chosen 'metric' does not exist")
    end # if
end # function

# -----------------------------------------------------------
# 2. Distances
# -----------------------------------------------------------

"""
    (1) distanceSqr(P::‚Ñç, metric::Metric=Fisher
    (2) distanceSqr(P::‚Ñç, Q::‚Ñç, metric::Metric=Fisher)

 **alias**: `distance¬≤`

 (1) Return ``Œ¥^2(P, I)``, the *square of the distance* (or *divergence*) of positive definite
 matrix ``P`` from the the identity matrix. See [distance from the origin](@ref).

 (2) Return ``Œ¥^2(P, Q)``, the *square of the distance* (or *divergence*) between two
 positive definite matrices ``P`` and ``Q``. See [distance](@ref).

 In both cases the distance function ``Œ¥`` is induced by the argument `metric` of type
 [Metric::Enumerated type](@ref). By default, the [Fisher](@ref) metric is adopted.

 The distance is always real, non-negative and equal to zero if and only if
 (1) ``P=I`` or (2) ``P=Q``.

 ``P`` in (1) and ``P``, ``Q`` in (2) must be flagged by julia as `Hermitian`.
 See [typecasting matrices](@ref).

 **Maths**

 For point ``P`` the *squared distances from the identity*
 for the supported metrics are:

| Metric   | Squared Distance from the identity |
|:----------:|:----------- |
|Euclidean | ``‚à•P-I‚à•^2`` |
|invEuclidean| ``‚à•P^{-1}-I‚à•^2``|
|ChoEuclidean| ``‚à•L_P-I‚à•^2``|
|logEuclidean| ``‚à•\\textrm{log}P‚à•^2`` |
|logCholesky| ``‚à•S_P‚à•^2+‚à•\\textrm{log}D_P‚à•^2`` |
|Fisher | ``‚à•\\textrm{log}P‚à•^2`` |
|logdet0| ``\\textrm{logdet}\\frac{1}{2}(P+I) - \\frac{1}{2}\\textrm{logdet}(P)`` |
|Jeffrey | ``\\frac{1}{2}\\textrm{tr}(P+P^{-1})-n `` |
|VonNeumann | ``\\frac{1}{2}\\textrm{tr}(P\\textrm{log}P-\\textrm{log}P)``|
|Wasserstein| ``\\textrm{tr}(P+I) -2\\textrm{tr}(P^{1/2})`` |

 For points ``P`` and ``Q`` their *squared distances* for the supported metrics are:

| Metric   | Squared Distance |
|:----------:|:----------- |
|Euclidean | ``‚à•P-Q‚à•^2`` |
|invEuclidean| ``‚à•P^{-1}-Q^{-1}‚à•^2``|
|ChoEuclidean| ``‚à• L_P - L_Q ‚à•^2``|
|logEuclidean| ``‚à•\\textrm{log}P-\\textrm{log}Q‚à•^2`` |
|logCholesky| ``‚à•S_P-S_Q‚à•^2+‚à•\\textrm{log}D_P-\\textrm{log}D_Q‚à•^2`` |
|Fisher | ``‚à•\\textrm{log}(P^{-1/2}QP^{-1/2})‚à•^2``|
|logdet0| ``\\textrm{logdet}\\frac{1}{2}(P+Q) - \\frac{1}{2}\\textrm{logdet}(PQ)`` |
|Jeffrey | ``\\frac{1}{2}\\textrm{tr}(Q^{-1}P+P^{-1}Q)-n `` |
|VonNeumann | ``\\frac{1}{2}\\textrm{tr}(P\\textrm{log}P-P\\textrm{log}Q+Q\\textrm{log}Q-Q\\textrm{log}P)``|
|Wasserstein| ``\\textrm{tr}(P+Q) -2\\textrm{tr}(P^{1/2}QP^{1/2})^{1/2}`` | ``\\textrm{tr}(P+Q) -2\\textrm{tr}(P^{1/2}QP^{1/2})^{1/2}`` |

  **legend:** ``L_X``, ``S_X`` and ``D_X``
  are the Cholesky lower triangle of ``X``, its strictly lower triangular part
  and diagonal part, respectively (hence, ``S_X+D_X=L_X``,  ``L_XL_X^*=X``).

 **See also**: [`distanceSqrMat`](@ref)

 ## Examples (1)
    using PosDefManifold
    P=randP(10);
    d=distanceSqr(P, Wasserstein)
    e=distanceSqr(P) # uses the default metric (Fisher)
    metric=Metric(Int(logdet0)) # or metric=logdet0
    s=string(metric) # check what is the current metric
    f=distance¬≤(P, metric) #using the alias distance¬≤

 ## Examples (2)
    using PosDefManifold
    P=randP(10);
    Q=randP(10);
    d=distanceSqr(P, Q, Wasserstein)
    e=distance¬≤(P, Q, Jeffrey)

"""
function distanceSqr(P::‚Ñç, metric::Metric=Fisher)
    if      metric==Euclidean
    return  sumOfSqr(P-I)

    elseif  metric==invEuclidean
    return  sumOfSqr(inv(P)-I)

    elseif  metric in (logEuclidean, Fisher)
    return  ùö∫(log.(eigvals(P)).^2)

    elseif  metric==logdet0
    return  real(logdet((P+I)/2) - logdet(P)/2)

    elseif  metric==ChoEuclidean
    return  sumOfSqr(choL(P)-I)

    elseif  metric==logCholesky
            LP=choL(P)
            n=size(P, 1)
    return  sumOfSqrTril(tril(LP,-1), -1) + ùö∫(log(LP[i, i])^2 for i in 1:n)

    elseif  metric==Jeffrey
    return  tr(P)/2 + tr(inv(P))/2 - size(P, 1)

    elseif  metric==VonNeumann # see squared distance
            ùìµP=log(P)
    return  (tr(P*ùìµP) - tr(ùìµP))/2

    elseif  metric==Wasserstein
    return  tr(P+I) - 2*tr(sqrt(P))

    else    @warn("in RiemannianGeometryP.distanceSqr function
             (PosDefManifold Package): the chosen 'metric' does not exist")
    end # if
end #function

function distanceSqr(P::‚Ñç, Q::‚Ñç, metric::Metric=Fisher)
    if      metric==Euclidean
    return  sumOfSqr(P - Q)

    elseif  metric==invEuclidean
    return  sumOfSqr(inv(P) - inv(Q))

    elseif  metric==logEuclidean
    return  sumOfSqr(log(P) - log(Q))

    elseif  metric==Fisher
    return  ùö∫(log.(eigvals(P, Q)).^2)

    elseif  metric==logdet0
    return  real(logdet((P + Q) / 2) - logdet(P * Q)/2)

    elseif  metric==ChoEuclidean
    return  sumOfSqr(choL(P)-choL(Q))

    elseif  metric==logCholesky
            LP = choL(P)
            LQ = choL(Q)
            n=size(P, 1)
    return  sumOfSqrTril(tril(LP,-1)-tril(LQ,-1), -1)+ùö∫((log(LP[i, i])-log(LQ[i, i]))^2 for i in 1:n)

    elseif  metric==Jeffrey
    return  real(tr(inv(Q)*P)/2 + tr(inv(P)*Q)/2) - size(P, 1)

    elseif  metric==VonNeumann      # using formula: tr(PlogP - PlogQ + QlogQ - QlogP)/2=
            ùìµPmùìµQ=log(P)-log(Q);         # (tr(P(logP - LoqQ)) + tr(Q(logQ - logP)))/2=
    return  (tr(P*ùìµPmùìµQ) - tr(Q*ùìµPmùìµQ))/2     # (tr(P(logP - LoqQ)) - tr(Q(logP - LoqQ)))/2

    elseif  metric==Wasserstein
            P¬Ω=sqrt(P);
    return  tr(P) + tr(Q) -2tr(sqrt(‚Ñç(P¬Ω*Q*P¬Ω)))

    else    @warn("in RiemannianGeometryP.distanceSqr function
                    (PosDefManifold Package): the chosen 'metric' does not exist")
    end #if
end # function
distance¬≤=distanceSqr # alias


"""
    (1) distance(P::‚Ñç, metric::Metric=Fisher
    (2) distance(P::‚Ñç, Q::‚Ñç, metric::Metric=Fisher)

 (1) Return ``Œ¥(P, I)``, the *distance* between positive definite matrix ``P`` and
 the identity matrix.

 (2) Return ``Œ¥(P, Q)``, the *distance* between positive definite
 matrices ``P`` and ``Q``.

 This is the square root of [`distanceSqr`](@ref)
 and is invoked with the same syntax therein.

 **See also**: [`distanceMatrix`](@ref)
"""
distance(P::‚Ñç, metric::Metric=Fisher) = ‚àö(distanceSqr(P, metric))
distance(P::‚Ñç, Q::‚Ñç, metric::Metric=Fisher) = ‚àö(distanceSqr(P, Q, metric))

# -----------------------------------------------------------
# 3. Inter-distance matrix, Laplacian and Spectral Embedding
# -----------------------------------------------------------

# Internal Function for fast computation of inter_distance matrices
function GetdistanceSqrMat(‚Ñò, metric::Metric=Fisher)
    k=length(‚Ñò)
    n=size(‚Ñò[1], 1)
    ‚ñ≥=zeros(k,  k)

    if      metric==invEuclidean
            ‚Ñòùì≤=[inv(P) for P in ‚Ñò]
            for j in 1:k-1, i in j+1:k
                ‚ñ≥[i, j]=sumOfSqr(‚Ñòùì≤[i] - ‚Ñòùì≤[j])  end

    elseif  metric==logEuclidean
            ‚Ñòùìµ=[log(P) for P in ‚Ñò]
            for j in 1:k-1, i in j+1:k
                ‚ñ≥[i, j]=sumOfSqr(‚Ñòùìµ[i] - ‚Ñòùìµ[j])  end

    elseif  metric==ChoEuclidean
            ‚ÑòL=[choL(P) for P in ‚Ñò]
            for j in 1:k-1, i in j+1:k
                ‚ñ≥[i, j]=sumOfSqr(‚ÑòL[i] - ‚ÑòL[j])  end

    elseif  metric==logCholesky
            ‚ÑòL=[choL(P)     for P in ‚Ñò]
            for j in 1:k-1, i in j+1:k
                ‚ñ≥[i, j]=sumOfSqrTril(‚ÑòL[i]-‚ÑòL[j], -1) + ùö∫((log(‚ÑòL[i][l, l])-log(‚ÑòL[j][l, l]))^2 for l in 1:n) end

    elseif  metric==Jeffrey
            ‚Ñòùì≤=[inv(P) for P in ‚Ñò]
            for j in 1:k-1, i in j+1:k
                ‚ñ≥[i, j]=tr(‚Ñòùì≤[j]*‚Ñò[i])/2 + tr(‚Ñòùì≤[i]*‚Ñò[j])/2 - n   end

    elseif  metric==VonNeumann  # using formula: tr( PlogP + QLoqQ - PlogQ - QlogP)
            ùìµ‚Ñò=[log(P)      for P in ‚Ñò]
            ‚Ñòiùìµ‚Ñòi=[P*log(P) for P in ‚Ñò]
            for j in 1:k-1, i in j+1:k
                ‚ñ≥[i, j]=(tr(‚Ñòiùìµ‚Ñòi[i])+tr(‚Ñòiùìµ‚Ñòi[j])-tr(‚Ñò[i] * ùìµ‚Ñò[j])-tr(‚Ñò[j] * ùìµ‚Ñò[i]))/2   end

    elseif  metric==Wasserstein
            ‚Ñò¬Ω=[sqrt(P) for P in ‚Ñò]
            for j in 1:k-1, i in j+1:k
                ‚ñ≥[i, j]=tr(‚Ñò[i]) + tr(‚Ñò[j]) -2*tr(sqrt(‚Ñò¬Ω[i] * ‚Ñò[j] * ‚Ñò¬Ω[i]'))     end

    elseif  metric in (Euclidean, Fisher, logdet0)
            for j in 1:k-1, i in j+1:k
                ‚ñ≥[i, j]=distanceSqr(‚Ñò[i], ‚Ñò[j], metric)  end

    else    @warn("in RiemannianGeometryP.distanceSqrMat or .distanceMatrix function
                         (PosDefManifold Package): the chosen 'metric' does not exist")

    end # If

    return ‚ñ≥
end #function



"""
    distanceSqrMat(‚Ñò, metric::Metric=Fisher)

 **alias**: `distance¬≤Mat`

 Given a 1d array `‚Ñò` of ``k`` positive definite matrices
 ``{P_1,...,P_k}``, create the ``k‚ãÖk`` real `Hermitian` matrix comprising
 elements ``Œ¥^2(P_i, P_j)\\textrm{, for all }i‚â†j``.

 This is the matrix of all *squared inter-distances* (zero on diagonal), using the
 specified `metric`, of type [Metric::Enumerated type](@ref),
 giving rise to distance function ``Œ¥``. See [`distanceSqr`](@ref).
 By default, the [Fisher](@ref) metric is adopted.

 **See also**: [`laplacian`](@ref), [`laplacianEigenMaps`](@ref), [`spectralEmbedding`](@ref).

 ## Examples
    using PosDefManifold
    # Generate a set of 4 random 10x10 SPD matrices
    ‚Ñò=randP(10, 4)
    # Compute the squared inter-distance matrix according to the log Euclidean metric.
    # This is much faster as compared to the Fisher metric and in general
    # it is a good approximation.
    Œî¬≤=distanceSqrMat(‚Ñò, logEuclidean)

"""
distanceSqrMat(‚Ñò, metric::Metric=Fisher)=‚Ñç(GetdistanceSqrMat(‚Ñò, metric), :L)
distance¬≤Mat=distanceSqrMat


"""
    distanceMatrix(‚Ñò, metric::Metric=Fisher)

 **alias**: `distanceMat`

 Given a 1d array `‚Ñò` of ``k`` positive definite matrices
 ``{P_1,...,P_k}``, create the ``k‚ãÖk`` real `Hermitian` matrix comprising elements
 ``Œ¥(P_i, P_j)\\textrm{, for all }i‚â†j``.

 This is the matrix of all *inter-distances* (zero on diagonal), using the
 specified `metric`, of type [Metric::Enumerated type](@ref),
 giving rise to distance ``Œ¥``. See [`distance`](@ref).
 By default, the [Fisher](@ref) metric is adopted.

 The elements of this matrix are the square root of
 [`distanceSqrMat`](@ref).

 ## Examples
    using PosDefManifold
    # Generate a set of 4 random 10x10 SPD matrices
    ‚Ñò=randP(10, 4)
    Œî=distanceMatrix(‚Ñò)
"""
distanceMatrix(‚Ñò, metric::Metric=Fisher)=‚Ñç(sqrt.(GetdistanceSqrMat(‚Ñò, metric)), :L)
distanceMat=distanceMatrix


"""
    laplacian(Œî¬≤)

 Given a matrix of squared inter-distances ``Œî^2``,
 computed for examples by function [`distanceSqrMat`](@ref),
 return the *normalized Laplacian*.

 First, a [Gaussian radial basis functions](https://bit.ly/1HVyf55)
 is applied to all elements of ``Œî^2``, such as

 ``W_{ij} = exp(\\frac{\\displaystyle{-Œî^2_{ij}}}{\\displaystyle{Œµ}})``,

  where ``Œµ`` is the Gaussian scale parameter chosen automatically
  as the median of the elements ``Œî^2_{ij}``.

  Finally, the normalized Laplacian is defined as

 ``Œ© = D^{-1/2}WD^{-1/2}``,

  where ``D`` is the diagonal matrix holding on the main diagonal
  the sum of the rows (or columns) of ``W``.

!!! note "Nota Bene"
    The normalized Laplacian as here defined can be requested for any
    input matrix of squared inter-distances, for example,
    those obtained on scalars or on vectors using appropriate metrics.

 **See also**: [`distanceSqrMat`](@ref), [`laplacianEigenMaps`](@ref), [`spectralEmbedding`](@ref).

 ## Examples
    using PosDefManifold
    # Generate a set of 4 random 10x10 SPD matrices
    ‚Ñò=randP(10, 4)
    Œî¬≤=distanceSqrMat(‚Ñò)
    Œ©=laplacian(Œî¬≤) # or, equivalently, Œ©=RŒ©(Œî)

 """
function laplacian(Œî¬≤)
    (r, c)=size(Œî¬≤)
    epsilon=median([Œî¬≤[i, j] for j=1:c-1 for i=j+1:r]) # use geometric mean instead
    L=Matrix{eltype(Œî¬≤)}(undef, r, c)
    for i=1:r L[i, i]=1.0 end
    for j=1:c-1, i=j+1:r L[i, j]=exp(-Œî¬≤[i, j]/epsilon)  end
    W=‚Ñç(L, :L)
    Dnorms=Diagonal([1/(‚àö(ùö∫(W[:, j]))) for j=1:c])
    return ‚Ñç(Dnorms * W * Dnorms) # Œ©
end


"""
    laplacianEigenMaps(Œ©, q::Int; <tol=1e-9, maxiter=300, ‚ç∞=false>)

 **alias**: `laplacianEM`

 Given a normalized Laplacian ``Œ©`` (see [`laplacian`](@ref) ) return
 the *eigen maps* in ``q`` dimensions, i.e., the ``q`` eigenvectors of
 the normalized Laplacian associated with the largest ``q``
 eigenvalues, excluding the first (which is always equal to 1.0).

 The eigenvectors of the normalized Laplacian are computed by the
 power iterations+modified Gram-Schmidt method,
 allowing calling this function even for big Laplacian matrices.

 Return the 4-tuple ``(Œõ, U, iterations, convergence)``, where:
 - ``Œõ`` is a ``q‚ãÖq`` diagonal matrix holding on diagonal the eigenvalues corresponding to the ``q`` dimensions of the Laplacian eigen maps;
 - ``U`` holds in columns the eigen maps, that is, the ``q`` eigenvectors
 - ``iterations`` is the number of iterations executed by the power method;
 - ``convergence`` is the convergence attained by the power method;

 The eigenvectors of ``U`` holds the coordinates of the points in the
 embedded space. For examples of applications see Ridrigues et al. (2018) [üéì](@ref).

!!! note "Nota Bene"
    The maximum value of ``q`` that can be requested is ``n-1``,
    where ``n`` is the size of the Laplacian.
    In general, ``q=2`` or ``q=3`` is requested.


 **Arguments**: `(Œ©, q; <tol=1e-9, maxiter=300, ‚ç∞=false>)`:
 - ``Œ©`` is a normalized Laplacian obtained by the [`laplacian`](@ref) function;
 - ``q`` is the dimension of the Laplacian eigen maps;
 - The following are *<optional keyword arguments>* for the power method iterative algorithm:
   * `tol` is the tolerance for convergence;
   * `maxiter` is the maximum number of iterations allowed;
   * if `‚ç∞` is true, the convergence at all iterations will be printed.

 **See also**: [`distanceSqrMat`](@ref), [`laplacian`](@ref), [`spectralEmbedding`](@ref).

 ## Examples
    using PosDefManifold
    # Generate a set of 4 random 10x10 SPD matrices
    ‚Ñò=randP(10, 4)
    evalues, maps, iterations, convergence=laplacianEM(Œ©, 2)
    evalues, maps, iterations, convergence=laplacianEM(Œ©, 2, maxiter=500)
    evalues, maps, iterations, convergence=laplacianEM(Œ©, 2, ‚ç∞=true)

"""
function laplacianEigenMaps(Œ©, q::Int; tol=1e-9, maxiter=300, ‚ç∞=false)
    (Œõ, U, iter, conv) =
        powIter(Œ©, q+1; evalues=true, tol=tol, maxiter=maxiter, ‚ç∞=‚ç∞)
    return Diagonal(Œõ[2:q+1, 2:q+1]), U[1:size(U, 1), 2:q+1], iter, conv
end;
laplacianEM=laplacianEigenMaps


"""
    spectralEmbedding(‚Ñò, q::Int, metric::Metric=Fisher;
                        <tol=1e-9, maxiter=300, ‚ç∞=false>)

 **alias**: `Rse`

 Given a 1d array `‚Ñò` of ``k`` positive definite matrices ``{P_1,...,P_k}``,
 compute its *eigen maps* in ``q`` dimensions.

 This function runs one after the other the functions:
 - [`distanceSqrMat`](@ref) (compute the squared inter-distance matrix),
 - [`laplacian`](@ref) (compute the normalized Laplacian),
 - [`laplacianEigenMaps`](@ref) (get the eigen maps).

  Return the 4-tuple `(Œõ, U, iterations, convergence)`, where:
 - ``Œõ`` is a ``q‚ãÖq`` diagonal matrix holding on diagonal the eigenvalues corresponding to the ``q`` dimensions of the Laplacian eigen maps;
 - ``U`` holds in columns the ``q`` eigenvectors, i.e., the ``q`` coordinates of the points in the embedded space.
 - ``iterations`` is the number of iterations executed by the power method;
 - ``convergence`` is the convergence attained by the power method;

 **Arguments** `(‚Ñò, q, metric, <tol=1e-9, maxiter=300, ‚ç∞=false>)`:
 - `‚Ñò` is a 1d array of ``k`` positive matrices;
 - ``q`` is the dimension of the Laplacian eigen maps;
 - `metric` is a metric of type [Metric::Enumerated type](@ref),
   used for computing the inter-distances. By default, the [Fisher](@ref) metric is adopted.
 - The following are *<optional keyword arguments>* for the power method iterative algorithm:
   * `tol` is the tolerance for convergence of the power method;
   * `maxiter` is the maximum number of iterations allowed for the power method;
   * if `‚ç∞` is true the convergence at all iterations will be printed.

 **See also**: [`distanceSqrMat`](@ref), [`laplacian`](@ref), [`laplacianEigenMaps`](@ref).

 ## Examples
    using PosDefManifold
    # Generate a set of 4 random 10x10 SPD matrices
    ‚Ñò=randP(10, 4)
    evalues, maps, iterations, convergence=spectralEmbedding(‚Ñò, 2)
    evalues, maps, iterations, convergence=spectralEmbedding(‚Ñò, 2, ‚ç∞=true)

"""
function spectralEmbedding(‚Ñò, q::Int, metric::Metric=Fisher;
                            tol=1e-9, maxiter=300, ‚ç∞=false)
    return (Œõ, U, iter, conv) =
            laplacianEM(laplacian(distance¬≤Mat(‚Ñò, metric)), q; tol=tol, maxiter=maxiter, ‚ç∞=‚ç∞)
end


# -----------------------------------------------------------
# 4. Means (centers of mass, barycenters, ...)
# -----------------------------------------------------------

# Internal functions
Attributes(‚Ñò)=( size(‚Ñò[1], 1), length(‚Ñò))
#Attributes(‚Ñò)=(‚Ñò[1] isa Hermitian ? Hermitian : Symmetric, size(‚Ñò[1], 1), length(‚Ñò))
#Attributes(P::HermOrSym)=(P isa Hermitian ? Hermitian : Symmetric, size(P, 1))


function DoNothing
end

function GetWeights(w::Vector, ‚úìw::Bool, k::Int)
    if ‚úìw==true
        s=ùö∫(w)
        if s ‚ââ  1.0 return w./s else return w end
    else return w
    end
end

"""
    generalizedMean(‚Ñò, p::Real; <w::Vector=[], ‚úìw::Bool=true>)

 Given a 1d array `‚Ñò` of ``k`` positive definite matrices``{P_1,...,P_k}``
 and optional non-negative real weights vector ``w={w_1,...,w_k}``,
 return the *weighted generalized mean* ``G`` with real parameter ``p``, that is,

 ``G=\\big(\\sum_{i=1}^{k}w_iP_i^p\\big)^{1/p}``.

 If you don't pass a weight vector with *<optional keyword argument>* ``w``,
 return the *unweighted generalized mean*.

 ``G=\\big(\\sum_{i=1}^{k}P_i^p\\big)^{1/p}``.

 If *<optional keword argument>* `‚úìw=true` (default), the weights are
 normalized so as to sum up to 1, otherwise they are used as they are passed.
 This option is provided to allow
 calling this function repeatedly without normalizing the weights each time.

 The following special cases for parameter ``p`` are noteworthy:
 - For ``p=\\frac{1}{2}`` the generalized mean is the [modified Bhattacharyya mean](@ref).
 - For ``p=1`` the generalized mean is the [Euclidean](@ref) mean.
 - For ``p=-1`` the generalized mean is the [inverse Euclidean](@ref) mean.
 - For ``p=0`` the generalized mean is the [log Euclidean](@ref) mean, which is the [Fisher](@ref) mean when matrices in `‚Ñò` all pair-wise commute.

 Notice that when matrices in `‚Ñò` all pair-wise commute,
 the generalized means coincide with the [power means](@ref)
 for any ``p‚àà[-1, 1]`` and for ``p=0.5`` it coincides also with the
 *Wasserstein* mean (see [`wasMean`](@ref)). For this reason the generalized means are used
 as default initialization of both the [`powerMean`](@ref) and [`wasMean`](@ref)
 algorithm.

 **See also**: [`powerMean`](@ref)

 ## Examples
    using LinearAlgebra, Statistics, PosDefManifold
    # Generate a set of 4 random 3x3 SPD matrices
    ‚Ñò=randP(3, 4)

    # weights vector, does not need to be normalized
    weights=[1, 2, 3, 1]

    # unweighted mean
    G = generalizedMean(‚Ñò, 0.25)

    # weighted mean
    G = generalizedMean(‚Ñò, 0.5; w=weights)

    # with weights previously normalized we can set ‚úìw=false
    weights=weights./mean(weights)
    G = generalizedMean(‚Ñò, 0.5; w=weights, ‚úìw=false)

"""
function generalizedMean(‚Ñò, p::Real; w::Vector=[], ‚úìw::Bool=true)
    if     p == -1 return meanP(‚Ñò, invEuclidean; w=w, ‚úìw=‚úìw)
    elseif p ==  0 return meanP(‚Ñò, logEuclidean; w=w, ‚úìw=‚úìw)
    elseif p ==  1 return meanP(‚Ñò, Euclidean;    w=w, ‚úìw=‚úìw)
    else
        n, k=Attributes(‚Ñò)
        if isempty(w)
            return ‚Ñç(‚Ñç(ùõç(P^p for P in ‚Ñò))^(1/p))
        else
            v=GetWeights(w, ‚úìw, k)
            return ‚Ñç(‚Ñç(ùö∫(œâ*P^p for (œâ, P) in zip(v, ‚Ñò)))^(1/p))
        end # if w
    end # if p
end # function


"""

    logdet0Mean(‚Ñò; <w::Vector=[], ‚úìw::Bool=true, init=nothing,
                     tol=1e-9, ‚ç∞=false>)

 Given a 1d array ``‚Ñò`` of ``k`` positive definite matrices ``{P_1,...,P_k}``
 and optional non-negative real weights vector ``w={w_1,...,w_k}``,
 return the 3-tuple ``(G, iter, conv)``, where ``G`` is the mean according
 to the [logdet zero](@ref) metric and ``iter``, ``conv`` are the number of iterations
 and convergence attained by the algorithm.
 Mean ``G`` is the unique positive definite matrix satisfying

 ``\\sum_{i=1}^{k}w_i\\big(\\frac{1}{2}P_i+\\frac{1}{2}G\\big)^{-1}=G^{-1}``.

 For estimating it, this function implements the fixed-point iteration algorithm
suggested by (Moakher, 2012, p315)[üéì](@ref), yielding iterations

 ``G ‚Üê \\frac{1}{2}\\big(\\sum_{i=1}^{k}w_i(P_i+G)^{-1}\\big)^{-1}``.

 If you don't pass a weight vector with *<optional keyword argument>* ``w``,
 return the *unweighted logdet zero mean*.

 If *<optional keword argument>* `‚úìw=true` (default), the weights are
 normalized so as to sum up to 1, otherwise they are used as they are passed
 and should be already normalized.  This option is provided to allow
 calling this function repeatedly without normalizing the same weights
 vector each time.

 The following are more *<optional keyword arguments*>:
 - `init` is a matrix to be used as initialization for the mean. If no matrix is provided, the [log Euclidean](@ref) mean will be used;
 - `tol` is the tolerance for the convergence. The smaller this number (it must be positive) the closer the algorithm gets to the saddle point;
 - if `‚ç∞` is true, the convergence attained at each iteration is printed.

!!! note "Nota Bene"
    In normal circumstances this algorithm converges monothonically.
    If the algorithm diverges a **warning** is printed indicating the iteration
    when this happened and the algorithm is interrupted.

 **See**: [logdet zero](@ref) metric, [modified Bhattacharyya mean](@ref).

 ## Examples
    using LinearAlgebra, PosDefManifold
    # Generate a set of 4 random 3x3 SPD matrices
    ‚Ñò=randP(3, 4)

    # unweighted mean
    G, iter, conv = logdet0Mean(‚Ñò)

    # weights vector, does not need to be normalized
    weights=[1, 2, 3, 1]

    # weighted mean
    G, iter, conv = logdet0Mean(‚Ñò, w=weights)

    # print the convergence at all iterations
    G, iter, conv = logdet0Mean(‚Ñò, w=weights, ‚ç∞=true)

    # now suppose ‚Ñò has changed a bit, initialize with G to hasten convergence
    ‚Ñò[1]=‚Ñç(‚Ñò[1]+(randP(3)/100))
    G, iter, conv = logdet0Mean(‚Ñò, w=weights, ‚úìw=false, ‚ç∞=true, init=G)

"""
function logdet0Mean(‚Ñò;    w::Vector=[], ‚úìw::Bool=true, init=nothing,
                            tol=1e-9, ‚ç∞=false)
    maxIter=500
    n, k = Attributes(‚Ñò)
    l=k/2
    isempty(w) ? v=[] : v = GetWeights(w, ‚úìw, k)
    init == nothing ? M = meanP(‚Ñò, logEuclidean, w=w, ‚úìw=false) : M = ‚Ñç(init)
    M‚óá = similar(M, eltype(M))
    iter = 1
    conv = 0.; oldconv=maxpos
    ‚ç∞ && @info("Iterating RlogDetMean Fixed-Point...")

    @inbounds while true
        if isempty(w)
            M‚óá = ‚Ñç(l * inv(‚Ñç(ùö∫(inv(‚Ñç(P+M)) for P in ‚Ñò))))
        else
            M‚óá = ‚Ñç(0.5 * inv(‚Ñç(ùö∫(œâ * inv(‚Ñç(P+M)) for (œâ, P) in zip(v, ‚Ñò)))))
        end
        conv = norm(M‚óá-M)/norm(M)
        ‚ç∞ && println("iteration: ", iter, "; convergence: ", conv)
        diverging = conv > oldconv
        diverging ? @warn("logdet0Mean diverged at:", iter) : oldconv=conv
        iter==maxIter || diverging || conv <= tol ? break : M = M‚óá
        iter += 1
    end # while

    return (M‚óá, iter, conv)
end


"""
    wasMean(‚Ñò; <w::Vector=[], ‚úìw::Bool=true, init=nothing,
                 tol=1e-9, ‚ç∞=false>)

 Given a 1d array `‚Ñò` of ``k`` positive definite matrices ``{P_1,...,P_k}``
 and optional non-negative real weights vector ``w={w_1,...,w_k}``,
 return the 3-tuple ``(G, iter, conv)``, where ``G`` is the mean according
 to the [Wasserstein](@ref) metric and ``iter``, ``conv`` are the number of iterations
 and convergence attained by the algorithm.
 Mean ``G`` is the unique positive definite matrix satisfying

 ``G=\\sum_{i=1}^{k}w_i\\big( G^{1/2}  P_i G^{1/2}\\big)^{1/2}``.

 For estimating it, this function implements the fixed-point iterative algorithm
 proposed by (√Ålvarez-Esteban et *al.*, 2016)[üéì](@ref):

 ``G ‚Üê G^{-1/2}\\big(\\sum_{i=1}^{k} w_i(G^{1/2}P_i G^{1/2})^{1/2}\\big)^2 G^{-1/2}``.

 If you don't pass a weight vector with *<optional keyword argument>* ``w``,
 return the *unweighted Wassertein mean*.

 If *<optional keword argument>* `‚úìw=true` (default), the weights are
 normalized so as to sum up to 1, otherwise they are used as they are passed
 and Metric::Enumerated type be already normalized.  This option is provided to allow
 calling this function repeatedly without normalizing the same weights
 vector each time.

 The following are more *<optional keyword arguments*>:
 - `init` is a matrix to be used as initialization for the mean. If no matrix is provided, the instance of [generalized means](@ref) with ``p=0.5`` will be used;
 - `tol` is the tolerance for the convergence. The smaller this number (it must be positive) the closer the algorithm gets to the true solution;
 - if `‚ç∞` is true, the convergence attained at each iteration is printed.

!!! note "Nota Bene"
    In normal circumstances this algorithm converges monothonically.
    If the algorithm diverges a **warning** is printed indicating the iteration
    when this happened and the algorithm is interrupted.

 **See**: [Wasserstein](@ref) metric

 ## Examples
    using LinearAlgebra, PosDefManifold
    # Generate a set of 4 random 3x3 SPD matrices
    ‚Ñò=randP(3, 4)

    # unweighted mean
    G, iter, conv = wasMean(‚Ñò)

    # weights vector, does not need to be normalized
    weights=[1, 2, 3, 1]

    # weighted mean
    G, iter, conv = wasMean(‚Ñò, w=weights)

    # print the convergence at all iterations
    G, iter, conv = wasMean(‚Ñò, w=weights, ‚ç∞=true)

    # now suppose ‚Ñò has changed a bit, initialize with G to hasten convergence
    ‚Ñò[1]=‚Ñç(‚Ñò[1]+(randP(3)/100))
    G, iter, conv = wasMean(‚Ñò, w=weights, ‚ç∞=true, init=G)

"""
function wasMean(‚Ñò;    w::Vector=[], ‚úìw::Bool=true, init=nothing,
                        tol=1e-9, ‚ç∞=false)
    maxIter=500
    n, k = Attributes(‚Ñò)
    isempty(w) ? v=[] : v = GetWeights(w, ‚úìw, k)
    init == nothing ? M = generalizedMean(‚Ñò, 0.5; w=v, ‚úìw=false) : M = ‚Ñç(init)
    M‚óá = similar(M, eltype(M))
    iter = 1
    conv = 0.; oldconv=maxpos
    ‚ç∞ && @info("Iterating wasMean Fixed-Point...")

    @inbounds while true
        S, W=pow(M, 0.5, -0.5)
        if isempty(w)
            M‚óá = ‚Ñç(W * sqr(‚Ñç(ùõç(sqrt(‚Ñç(S*P*S)) for P in ‚Ñò))) * W)
        else
            M‚óá = ‚Ñç(W * sqr(‚Ñç(ùö∫((sqrt(‚Ñç(S*P*S)) * œâ) for (œâ, P) in zip(v, ‚Ñò)))) * W)
        end
        conv = norm(M‚óá-M)/norm(M)
        ‚ç∞ &&  println("iteration: ", iter, "; convergence: ", conv)
        diverging = conv > oldconv
        diverging ? @warn("wasMean diverged at:", iter) : oldconv=conv
        iter==maxIter || diverging || conv <= tol ? break : M = M‚óá
        iter += 1
    end # while

    return (M‚óá, iter, conv)
end


"""
    powerMean(‚Ñò, p::Real; <w::Vector=[], ‚úìw::Bool=true, init=nothing,
                            tol=1e-9, ‚ç∞=false>)

 Given a 1d array `‚Ñò` of ``k`` positive definite matrices ``{P_1,...,P_k}``,
 an optional non-negative real weights vector ``w={w_1,...,w_k}`` and
 a real parameter `p` ``\\in[-1, 1]``, return the
 3-tuple ``(G, iter, conv)``, where ``G`` is
 Lim and Palfia (2012)'s [power means](@ref)  of order ``p`` and
 ``iter``, ``conv`` are the number of iterations
 and convergence attained by the algorithm, respectively.
 Mean ``G`` is the unique positive definite matrix satisfying

 ``G=\\sum_{i=1}^{k}(w_iG\\textrm{#}_pP_i)``,

 where ``G\\textrm{#}_pP_i`` is the [Fisher](@ref) geodesic equation.
 In particular:

 - with ``p=-1`` this is the *harmonic mean* (see the [inverse Euclidean](@ref))
 - with ``p=+1`` this is the *arithmetic mean* (see the [Euclidean](@ref))
 - at the limit of ``p`` evaluated at zero from both side this is the *geometric mean* (see the [Fisher](@ref) metric).

 For estimating power means for ``p\\in(-1, 1)``, this function implements
 the  fixed-point iterative algorithm of (Congedo et *al.*, 2017b)[üéì](@ref).
 For ``p=0`` (geometric mean)
 this algorithm is run two times with a small positive and negative value
 of ``p`` and the geometric mean of the two
 resulting means is returned, as suggested in (Congedo et *al.*, 2017b)[üéì](@ref).
 This way of estimating the geometric mean of
 a set of matrices is faster as compared to the usual gradient descent algorithm.

 If you don't pass a weight vector with *<optional keyword argument>* ``w``,
 return the *unweighted power mean*.

 If *<optional keword argument>* `‚úìw=true` (default), the weights are
 normalized so as to sum up to 1, otherwise they are used as they are passed
 and Metric::Enumerated type be already normalized.  This option is provided to allow
 calling this function repeatedly without normalizing the same weights
 vector each time.

 The following are more *<optional keyword arguments*>:
 - `init` is a matrix to be used as initialization for the mean. If no matrix is provided, the instance of [generalized means](@ref) with parameter ``p`` will be used.
 - `tol` is the tolerance for the convergence. The smaller this number (it must be positive) the closer the algorithm gets to the true solution;
 - if `‚ç∞` is true, the convergence attained at each iteration is printed.

!!! note "Nota Bene"
  In normal circumstances this algorithm converges monothonically.
  If the algorithm diverges a **warning** is printed indicating the iteration
  when this happened and the algorithm is interrupted.

 **See**: [modified Bhattacharyya mean](@ref)

 ## Examples
    using LinearAlgebra, PosDefManifold
    # Generate a set of 4 random 3x3 SPD matrices
    ‚Ñò=randP(3, 4)

    # unweighted mean
    G, iter, conv = powerMean(‚Ñò, 0.5)

    # weights vector, does not need to be normalized
    weights=[1, 2, 3, 1]

    # weighted mean
    G, iter, conv = powerMean(‚Ñò, 0.5, w=weights)

    # print the convergence at all iterations
    G, iter, conv = powerMean(‚Ñò, 0.5, w=weights, ‚ç∞=true)

    # now suppose ‚Ñò has changed a bit, initialize with G to hasten convergence
    ‚Ñò[1]=‚Ñç(‚Ñò[1]+(randP(3)/100))
    G, iter, conv = powerMean(‚Ñò, 0.5, w=weights, ‚ç∞=true, init=G)

"""
function powerMean(‚Ñò, p::Real;     w::Vector=[], ‚úìw::Bool=true, init=nothing,
                                    tol=1e-9, ‚ç∞=false)
  if !(-1<=p<=1) @error("The parameter p for power means must be in range [-1...1]")
  else
    if     p ‚âà-1
            return (meanP(‚Ñò, InvEuclidean, w=w, ‚úìw=‚úìw), 1, 0)
    elseif p ‚âà 0
            LE=meanP(‚Ñò, logEuclidean, w=w, ‚úìw=‚úìw)
            P, iter1, conv1=powerMean(‚Ñò,  0.01, w=w, ‚úìw=‚úìw, init=LE, tol=tol, ‚ç∞=‚ç∞)
            Q, iter2, conv2=powerMean(‚Ñò, -0.01, w=w, ‚úìw=‚úìw, init=P, tol=tol, ‚ç∞=‚ç∞)
            return (geodesic(P, Q,  0.5,  Fisher), iter1+iter2, (conv1+conv2)/2)
    elseif p ‚âà 1
                return (meanP(‚Ñò, Euclidean, w=w, ‚úìw=‚úìw), 1, 0)
    else
        # Set Parameters
        maxIter=500
        n, k = Attributes(‚Ñò)
        sqrtn=‚àön
        absp=abs(p)
        r=-0.375/absp
        w‚â†[] ? v = GetWeights(w, ‚úìw, k) : v=[]
        init == nothing ? M = generalizedMean(‚Ñò, p; w=v, ‚úìw=false) : M = ‚Ñç(init)
        p<0 ? X=‚Ñç(M^(0.5)) : X=‚Ñç(M^(-0.5))
        X‚óá, H = similar(X, eltype(X))
        ùí´=similar(‚Ñò, eltype(‚Ñò))
        if p<0 ùí´=[‚Ñç(inv(P)) for P in ‚Ñò] else ùí´=‚Ñò end
        iter = 1
        conv = 0.; oldconv=maxpos
        ‚ç∞ && @info("Iterating powerMean Fixed-Point...")

        @inbounds while true
            if isempty(w)
                H=‚Ñç(ùõç(pow(‚Ñç(X*P*X), absp) for P in ùí´))
            else
                H=‚Ñç(ùö∫(œâ * pow(‚Ñç(X*P*X), absp) for (œâ, P) in zip(v, ùí´)))
            end
            X‚óá=(pow(H, r))*X
            conv=norm(H-I)/sqrtn # relative difference to identity
            ‚ç∞ &&  println("iteration: ", iter, "; convergence: ", conv)
            diverging = conv > oldconv
            diverging ? @warn("powerMean diverged at:", iter) : oldconv=conv
            iter==maxIter || diverging || conv <= tol ? break : X = X‚óá
            iter += 1
        end # while
    end # if

    if p<0  return ( ‚Ñç((X‚óá)'*X‚óá), iter, conv )
    else    return ( ‚Ñç(inv((X‚óá)'*X‚óá)), iter, conv ) end
  end # if !(-1<=p<=1)
end



"""
    (1) meanP(P::‚Ñç, Q::‚Ñç, metric::Metric=Fisher)
    (2) meanP(‚Ñò, metric::Metric=Fisher; <w::Vector=[], ‚úìw::Bool=true>)

 (1) Mean of two positive definite matrices, passed in arbitrary order as
 arguments ``P`` and ``Q``, using the specified `metric` of type
 [Metric::Enumerated type](@ref). By defult the [Fisher](@ref) metric is used.
 The order is arbitrary as all metrics implemented in **PosDefManifold** are symmetric.
 This is the midpoint of the geodesic.
 For the weighted mean of two positive definite matrices use instead
 the [`geodesic`](@ref) function.
 ``P`` and ``Q`` must be flagged as `Hermitian`. See [typecasting matrices](@ref).

 (2) [Fr√©chet mean](@ref) of an 1d array ``‚Ñò`` of ``k`` positive definite matrices``{P_1,...,P_k}``,
 with optional non-negative real weights ``w={w_1,...,w_k}`` using the specified
 `metric`as in (1).

 If you don't pass a weight vector with *<optional keyword argument>* ``w``,
 return the *unweighted mean*.

 If *<optional keword argument>* `‚úìw=true` (default), the weights are
 normalized so as to sum up to 1, otherwise they are used as they are passed
 and should be already normalized.  This option is provided to allow
 calling this function repeatedly without normalizing the same weights
 vector each time.

 ## Math

 The Fr√©chet mean of a set of ``k`` matrices ``{P_1, P_2,..., P_k}`` weighted by
 ``{w_1, w_2,..., w_k}:\\sum_{i=1}^{k}w_i=1`` for the supported metrics are,
 for those with closed form expression:

| Metric   | weighted Fr√©chet mean |
|:----------:|:----------- |
|Euclidean | ``\\sum_{i=1}^{k}w_i P_i`` |
|invEuclidean| ``\\big(\\sum_{i=1}^{k}w_i P_i^{-1}\\big)^{-1}``|
|ChoEuclidean| ``TT^*``, where ``T=bL_P + aL_Q`` |
|logEuclidean| ``\\textrm{exp}\\big(\\sum_{i=1}^{k}w_i\\hspace{1pt} \\textrm{log}P_i \\big)``|
|logCholesky| ``TT^*``, where `` T=\\sum_{i=1}^{k}(w_kS_k)+\\sum_{i=1}^{k}(w_k\\textrm{log}D_k)``|
|Jeffrey | ``A^{1/2}\\big(A^{-1/2}HA^{-1/2}\\big)^{1/2}A^{1/2}`` |

 and for those that verify an equation:

| Metric   | equation verified by the weighted Fr√©chet mean |
|:----------:|:----------- |
|Fisher | ``\\sum_{i=1}^{k}w_i\\textrm{log}\\big(G^{-1/2} P_k G^{-1/2}\\big)=0.``|
|logdet0| ``\\sum_{i=1}^{k}w_i\\big(\\frac{1}{2}P_i+\\frac{1}{2}G\\big)^{-1}=G^{-1}`` |
|VonNeumann | N.A.|
|Wasserstein| ``G=\\sum_{i=1}^{k}w_i\\big( G^{1/2}  P_i G^{1/2}\\big)^{1/2}`` |

 **legend:** ``L_X``, ``S_X`` and ``D_X``
  are the Cholesky lower triangle of ``X``, its strictly lower triangular part
  and diagonal part, respectively (hence, ``S_X+D_X=L_X``,  ``L_XL_X^*=X``).
  ``A`` and ``H`` are the weighted arithmetic and weighted harmonic mean, respectively.

 **See**: [geodesic](@ref), [mean](@ref).

 ## Examples
    using LinearAlgebra, Statistics, PosDefManifold
    # Generate 2 random 3x3 SPD matrices
    P=randP(3)
    Q=randP(3)
    M=meanP(P, Q, logdet0) # (1)
    M=meanP(P, Q) # (1), uses Fisher metric

    # Generate a set of 4 random 3x3 SPD matrices
    ‚Ñò=randP(3, 4)
    # weights vector, does not need to be normalized
    weights=[1, 2, 3, 1]
    M=meanP(‚Ñò, Euclidean, w=weights) # (2) weighted Euclidean mean
    M=meanP(‚Ñò, Wasserstein)  # (2) unweighted Wassertein mean

"""
meanP(P::‚Ñç, Q::‚Ñç, metric::Metric=Fisher) = geodesic(P, Q, 0.5, metric)

function meanP(‚Ñò, metric::Metric=Fisher;    w::Vector=[], ‚úìw::Bool=true)
    # iterative solutions
    if      metric == Fisher
            (G, iter, conv)=powerMean(‚Ñò, 0; w=w, ‚úìw=‚úìw)
            return G
    elseif  metric == logdet0
            (G, iter, conv)=logdet0Mean(‚Ñò; w=w, ‚úìw=‚úìw)
            return G
    elseif  metric == Wasserstein
            (G, iter, conv)=wasMean(‚Ñò; w=w, ‚úìw=‚úìw)
            return G
    end

    # closed-form expressions
    n, k = Attributes(‚Ñò)
    isempty(w) ? DoNothing : v = GetWeights(w, ‚úìw, k)
    if  metric == Euclidean
        if isempty(w)   return ‚Ñç(ùõç(P for P in ‚Ñò))
        else            return ‚Ñç(ùö∫(œâ*P for (œâ, P) in zip(v, ‚Ñò)))
        end

    elseif metric == invEuclidean
        if isempty(w)   return ‚Ñç(inv(‚Ñç(ùõç(inv(P) for P in ‚Ñò))))
        else            return ‚Ñç(inv(‚Ñç(ùö∫(œâ*inv(P) for (œâ, P) in zip(v, ‚Ñò)))))
        end

    elseif metric == logEuclidean
        if isempty(w)   return ‚Ñç(exp(‚Ñç(ùõç(log(P) for P in ‚Ñò))))
        else            return ‚Ñç(exp(‚Ñç(ùö∫(œâ*log(P) for (œâ, P) in zip(v, ‚Ñò)))))
        end

    elseif metric == ChoEuclidean
        if isempty(w)   L = ùõç(choL(P) for P in ‚Ñò)
        else            L = ùö∫(œâ*choL(P) for (œâ, P) in zip(v, ‚Ñò))
        end
        return ‚Ñç(L*L')

    elseif metric == logCholesky # Aggiusta!
        L‚Ñò=[choL(P) for P in ‚Ñò]
        #if œâ==0 L=mean(tril(L‚Ñò[i],-1)      for i in 1:k) + exp(mean(ùëìùë´(L‚Ñò[i], log)      for i in 1:k))
        if isempty(w)
            L=ùõç(tril(L‚Ñò[i],-1) for i in 1:k)
            for l in 1:n L[l, l] = exp(ùõç(log(L‚Ñò[i][l, l]) for i in 1:k)) end
        #else    L=ùö∫(Œ∂[i]*tril(L‚Ñò[i],-1) for i in 1:k)/k + exp(ùö∫(ùëìùë´(Œ∂[i]*L‚Ñò[i], log) for i in 1:k))/k end
        else
            L=ùõç(v[i]*tril(L‚Ñò[i],-1) for i in 1:k)
            for l in 1:n L[l, l] = exp(ùö∫(v[i]*log(L‚Ñò[i][l, l]) for i in 1:k)) end
        end
        return ‚Ñç(L*L')

    elseif metric == Jeffrey
        P=meanP(‚Ñò, Euclidean; w=w, ‚úìw=‚úìw)
        Q=meanP(‚Ñò, invEuclidean; w=w, ‚úìw=‚úìw)
        P¬Ω, P‚Åª¬Ω=pow(P, 0.5, -0.5)
        return ‚Ñç(P¬Ω * sqrt(‚Ñç(P‚Åª¬Ω * Q * P‚Åª¬Ω)) * P¬Ω)

    elseif metric == VonNeumann
        @warn "function RiemannianGeometryP.meanP and .geodesic not defined for metric $metric"

    else
        @warn "in RiemannianGeometryP.meanP function: the chosen 'metric' does not exist"
    end # if metric
end # function


# -----------------------------------------------------------
# 5. Tangent Space Tools
# -----------------------------------------------------------

"""
    logMap(P::‚Ñç, G::‚Ñç, metric::Metric=Fisher)

 *Logaritmic Map:* map a positive definite matrix ``P`` from the SPD or
 Hermitian manifold into the tangent space at base-point ``G`` using the [Fisher](@ref) metric.

 ``P`` and ``G`` must be flagged as `Hermitian`. See [typecasting matrices](@ref).

 The map is defined as

 `` Log_G(P)=S=G^{1/2}\\textrm{log}\\big(G^{-1/2}PG^{-1/2}\\big)G^{1/2}``.

 The result is an `Hermitian` matrix.
 The inverse operation is [`expMap`](@ref).

 **Arguments** `(P, G, metric)`:
 - ``P`` is the positive definite matrix to be projected onto the tangent space,
 - ``G`` is the tangent space base point,
 - `metric` is a metric of type [Metric::Enumerated type](@ref).

 Currently only the [Fisher](@ref) metric is supported for tangent space operations.

 **See also**: [`vecP`](@ref)

 ## Examples
    using PosDefManifold
    P=randP(3)
    Q=randP(3)
    G=meanP(P, Q)
    # projecting P at the base point given by the geometric mean of P and Q
    S=logMap(P, G)
"""
function logMap(P::‚Ñç, G::‚Ñç, metric::Metric=Fisher)
    if   metric==Fisher
         G¬Ω, G‚Åª¬Ω=pow(G, 0.5, -0.5)
         return ‚Ñç(G¬Ω * log(G‚Åª¬Ω * P * G‚Åª¬Ω') * G¬Ω')
    else @warn "in RiemannianGeometryP.logMap function:
                 only the Fisher metric is supported for the logarithmic map."
    end
end

"""

    expMap(S::‚Ñç, G::‚Ñç, metric::Metric=Fisher)

 *Exponential Map:* map an `Hermitian` matrix ``S`` from the tangent space at base
 point ``G`` into the SPD or Hermitian manifold (using the [Fisher](@ref) metric).

 ``S`` and ``G`` must be flagged as `Hermitian`. See [typecasting matrices](@ref).

 The map is defined as

 `` Exp_G(S)=P=G^{1/2}\\textrm{exp}\\big(G^{-1/2}SG^{-1/2}\\big)G^{1/2}``.

 The result is a positive definite matrix.
 The inverse operation is [`logMap`](@ref).

 **Arguments** `(S, G, metric)`:
 - ``S`` is a Hermitian matrix, real or complex, to be projected on the SPD or Hermitian manifold,
 - ``G`` is the tangent space base point,
 - `metric` is a metric of type [Metric::Enumerated type](@ref).

  Currently only the Fisher metric is supported for tangent space operations.

 ## Examples
    using PosDefManifold, LinearAlgebra
    P=randP(3)
    Q=randP(3)
    G=meanP(P, Q, Fisher)
    # projecting P on the tangent space at the Fisher mean base point G
    S=logMap(P, G)
    # adding the identity in the tangent space and reprojecting back onto the manifold
    H=expMap(‚Ñç(S+I), G)
"""
function expMap(S::‚Ñç, G::‚Ñç, metric::Metric=Fisher)
    if   metric==Fisher
         G¬Ω, G‚Åª¬Ω=pow(G, 0.5, -0.5)
         return ‚Ñç(G¬Ω * exp(G‚Åª¬Ω * S * G‚Åª¬Ω') * G¬Ω')
    else @warn "in RiemannianGeometryP.expMap function:
              only the Fisher metric is supported for the exponential map"
    end
end


"""
    vecP(S::‚Ñç)

 *Vectorize* a tangent vector (matrix) ``S`` (*i.e.*, an `Hermitian` matrix):  mat -> vec.

 It gives weight ``1`` to diagonal elements and ‚àö2 to off-diagonal elements
 (Barachant et al., 2012)[üéì](@ref).

 The result is a vector holding ``n(n+1)/2`` elements, where ``n``
 is the size of ``S``.

 ``S`` must be flagged as Hermitian. See [typecasting matrices](@ref).

 The inverse operation is provided by [`matP`](@ref).

 ## Examples
    using PosDefManifold
    P=randP(3)
    Q=randP(3)
    G=meanP(P, Q, Fisher)
    # projecting P at the base point given by the geometric mean of P and Q
    S=logMap(P, G)
    # vectorize S
    œÇ=vecP(S)
"""
vecP(S::‚Ñç)=[(if i==j return S[i, j] else return (S[i, j])*sqrt2 end) for j=1:size(S, 2) for i=j:size(S, 1)]


"""
    matP(œÇ::Vector)

 *Matrizize* a tangent vector (vector) œÇ :  vec -> mat.

 This is the function reversing the [`vecP`](@ref) function,
 thus the weighting applied therein is reversed as well.

 If ``œÇ=vecP(S)`` and ``S`` is a ``n‚ãÖn`` Hermitian matrix,
 ``œÇ``  is a tangent vector of size ``n(n+1)/2``.
 The result of calling ``matP(œÇ)`` is then ``n‚ãÖn`` matrix ``S``.

 P.S.: This function needs to be rewritten more efficiently

 ## Examples
    using PosDefManifold
    P=randP(3)
    Q=randP(3)
    G=meanP(P, Q, Fisher)
    # projecting P at onto the tangent space at the Fisher mean base point
    S=logMap(P, G)
    # vectorize S
    œÇ=vecP(S)
    # Rotate the vector by an orthogonal matrix
    n=Int(size(S, 1)*(size(S, 1)+1)/2)
    U=randP(n)
    v=U*œÇ
    # Get the point in the tangent space
    S=matP(v)
"""
function matP(œÇ::Vector)
  n=Int((-1+‚àö(1+8*length(œÇ)))/2) # Size of the matrix whose vectorization vector v has size length(v)
  S=Matrix{eltype(œÇ)}(undef, n, n)
  l=0;
  for j in 1:n-1
    l=l+1
    @inbounds S[j, j]=œÇ[l]
    for i in j+1:n
      l=l+1
      @inbounds S[i, j]=invsqrt2*œÇ[l];  S[j, i]=S[i, j]
    end
  end
  S[n, n]=œÇ[end]
  return ‚Ñç(S)
end



# -----------------------------------------------------------
# 6. Procrustes Problems
# -----------------------------------------------------------

"""
    procrustes(P::‚Ñç, Q::‚Ñç, extremum="min")

 Given two positive definite matrices ``P`` and ``Q``,
 return by default the solution of problem

 ``\\textrm{argmin}_UŒ¥(P,U^*QU)``,

 where ``U`` varies over the set of unitary matrices ``ùêî`` and ``Œ¥(.,.)`` is a
 distance or divergence function.
 ``U^*QU`` is named in physics the *unitary orbit* of ``Q``.

 If the argument 'extremum' is passed as "max", it returns instead the solution of

 ``\\textrm{argmax}_UŒ¥(P,U^*QU)``.

  ``P`` and ``Q`` must be flagged as `Hermitian`. See [typecasting matrices](@ref).

 As it has been shown in Bhatia and Congedo (2019)[üéì](@ref),
 using each of the [Fisher](@ref), [logdet zero](@ref), [Wasserstein](@ref)
 and the Kullback-Leibler divergence (see [logdet Œ±](@ref)),
 the best approximant to ``P`` from the unitary orbit of ``Q``
 commutes with ``P`` and, surprisingly, has the same closed-form expression, namely

 ``U_Q^‚ÜìU_P^{‚Üì*}`` for the argmin and ``U_Q^‚ÜëU_P^{‚Üì*}`` for the argmax,

 where ``U^‚Üì`` denotes the eigenvector matrix of the subscript argument with
 eigenvectors in columns sorted by *decreasing* order of corresponding eigenvalues and
 ``U^‚Üë`` denotes the eigenvector matrix of the subscript argument with
 eigenvectors in columns sorted by *increasing* order of corresponding eigenvalues.

 The same solutions are known since a long time also by solving the extremal
 problem here above using the [Euclidean](@ref) metric (Umeyama, 1988).

 ## Examples
    using PosDefManifold
    P=randP(3)
    Q=randP(3)
    # argmin problem
    U=procrustes(P, Q)
    # argmax problem
    V=procrustes(P, Q, "max")
"""
function procrustes(P::‚Ñç, Q::‚Ñç, extremum="min")
    Pup=eigvecs(P)
    Qup=eigvecs(Q)
    Pdown=reverse(Pup, dims=(2))
    if      extremum=="min"
            Qdown=reverse(Qup, dims=(2))
            return Qdown*Pdown
    elseif  extremum=="max"
            return Qup*Pdown
    else    @warn "in RiemannianGeometryP.procrustes: the argument 'extremum' is incorrect."
    end
end
