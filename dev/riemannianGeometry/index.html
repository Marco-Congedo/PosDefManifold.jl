<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>riemannianGeometry.jl Â· PosDefManifold</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../index.html"><img class="logo" src="../assets/logo.png" alt="PosDefManifold logo"/></a><h1>PosDefManifold</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">PosDefManifold Documentation</a></li><li><a class="toctext" href="../introToRiemannianGeometry/">Intro to Riemannian Geometry</a></li><li><a class="toctext" href="../MainModule/">MainModule (PosDefManifold.jl)</a></li><li class="current"><a class="toctext" href>riemannianGeometry.jl</a><ul class="internal"><li><a class="toctext" href="#Geodesic-equations-1">Geodesic equations</a></li><li><a class="toctext" href="#Distances-1">Distances</a></li><li><a class="toctext" href="#Graphs-and-Laplacians-1">Graphs and Laplacians</a></li><li><a class="toctext" href="#Means-1">Means</a></li><li><a class="toctext" href="#Tangent-Space-operations-1">Tangent Space operations</a></li><li><a class="toctext" href="#Procrustes-problems-1">Procrustes problems</a></li></ul></li><li><a class="toctext" href="../linearAlgebra/">linearAlgebra.jl</a></li><li><a class="toctext" href="../statistics/">statistics.jl</a></li><li><a class="toctext" href="../signalProcessing/">signalProcessing.jl</a></li><li><a class="toctext" href="../test/">test.jl</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>riemannianGeometry.jl</a></li></ul><a class="edit-page" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/master/docs/src/riemannianGeometry.md"><span class="fa">ï‚›</span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>riemannianGeometry.jl</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="riemannianGeometry.jl-1" href="#riemannianGeometry.jl-1">riemannianGeometry.jl</a></h1><p>This is the fundamental unit of <strong>PosDefManifold</strong>. It contains functions for manipulating points in the Riemannian manifold of <em>Symmetric Positive Definite (SPD)</em> or <em>Hermitian Positive Definite (HPD)</em> matrices. In Julia those are <code>Hermitian</code> matrices, see <a href="../MainModule/#typecasting-matrices-1">typecasting matrices</a>.</p><p>The functions are divided in six categories:</p><table><tr><th>Category</th><th>Output</th></tr><tr><td>1. <a href="#Geodesic-equations-1">Geodesic equations</a></td><td>interpolation, extrapolation, weighted mean of two matrices, ...</td></tr><tr><td>2. <a href="#Distances-1">Distances</a></td><td>length of geodesics</td></tr><tr><td>3. <a href="#Graphs-and-Laplacians-1">Graphs and Laplacians</a></td><td>inter-distance matrices, spectral embedding, eigenmaps, ...</td></tr><tr><td>4. <a href="#Means-1">Means</a></td><td>mid-points of geodesics, FrÃ©chet means of several points</td></tr><tr><td>5. <a href="#Tangent-Space-operations-1">Tangent Space operations</a></td><td>maps from the manifold to the tangent space and viceversa, parallel transport,...</td></tr><tr><td>6. <a href="#Procrustes-problems-1">Procrustes problems</a></td><td>data matching, transfer learning (domain adaptation), ...</td></tr></table><p>â‹…</p><h2><a class="nav-anchor" id="Geodesic-equations-1" href="#Geodesic-equations-1">Geodesic equations</a></h2><table><tr><th>Function</th><th>Description</th></tr><tr><td><a href="#PosDefManifold.geodesic"><code>geodesic</code></a></td><td>Geodesic equations (weighted mean of two positive definite matrices) for any metric</td></tr></table><p>â‹…</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.geodesic" href="#PosDefManifold.geodesic"><code>PosDefManifold.geodesic</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">(1) geodesic(metric::Metric, P::â„{T}, Q::â„{T}, a::Real) where T&lt;:RealOrComplex
(2) geodesic(metric::Metric, D::ğ”»{S}, E::ğ”»{S}, a::Real) where S&lt;:Real</code></pre><p>(1) Move along the <a href="../introToRiemannianGeometry/#geodesic-1">geodesic</a> from point <span>$P$</span> to point <span>$Q$</span>  (two positive definite matrices) with <em>arclegth</em> <span>$0&lt;=a&lt;=1$</span>,  using the specified metric, of type <a href="../MainModule/#Metric::Enumerated-type-1">Metric::Enumerated type</a>.</p><p>For all metrics,</p><ul><li>with <span>$a=0$</span> we stay at <span>$P$</span>,</li><li>with <span>$a=1$</span> we move up to <span>$Q$</span>,</li><li>with <span>$a=1/2$</span> we move to the mid-point of <span>$P$</span> and <span>$Q$</span> (mean).</li></ul><p>Using the Fisher metric, argument <span>$a$</span> can be <em>any</em> real number, for instance:</p><ul><li>with <span>$0&lt;a&lt;1$</span> we move toward <span>$Q$</span> (<em>attraction</em>),</li><li>with <span>$a&gt;1$</span> we move over and beyond <span>$Q$</span> (<em>extrapolation</em>),</li><li>with <span>$a&lt;0$</span> we move back away from Q (<em>repulsion</em>).</li></ul><p><span>$P$</span> and <span>$Q$</span> must be flagged by julia as <code>Hermitian</code>.  See <a href="../MainModule/#typecasting-matrices-1">typecasting matrices</a>.</p><p>Note that if <span>$Q=I$</span>, the Fisher geodesic move is simply <span>$P^a$</span>  (no need to call this funtion then).</p><div class="admonition note"><div class="admonition-title">Nota Bene</div><div class="admonition-text"><p>For the <a href="../introToRiemannianGeometry/#logdet-zero-1">logdet zero</a> and <a href="../introToRiemannianGeometry/#Jeffrey-1">Jeffrey</a> metric no closed form expression for the geodesic is available to the best of authors&#39; knowledge, so in this case the geodesic is found as the weighted mean using the <a href="#Statistics.mean"><code>mean</code></a> function. For the <a href="../introToRiemannianGeometry/#Von-Neumann-1">Von Neumann</a> not even an expression for the mean is available, so in this case the geodesic is not provided and a <em>warning</em> is printed.</p></div></div><p>(2) Like in (1), but for two real positive definite diagonal matrices  <span>$D$</span> and <span>$E$</span>.</p><p><strong>Maths</strong></p><p>For points <span>$P$</span>, <span>$Q$</span> and arclength <span>$a$</span>, letting <span>$b=1-a$</span>,  the geodesic equations for the supported metrics are:</p><table><tr><th>Metric</th><th>geodesic equation</th></tr><tr><td>Euclidean</td><td><span>$bP + aQ$</span></td></tr><tr><td>invEuclidean</td><td><span>$\big(bP^{-1} + aQ^{-1}\big)^{-1}$</span></td></tr><tr><td>ChoEuclidean</td><td><span>$TT^*$</span>, where <span>$T=bL_P + aL_Q$</span></td></tr><tr><td>logEuclidean</td><td><span>$\text{exp}\big(b\hspace{2pt}\text{log}(P) + a\hspace{2pt}\text{log}(Q)\big)$</span></td></tr><tr><td>logCholesky</td><td><span>$TT^*$</span>, where <span>$T=S_P+a(S_Q-S_P)+D_P\hspace{2pt}\text{exp}\big(a(\text{log}D_Q-\text{log}D_P)\big)$</span></td></tr><tr><td>Fisher</td><td><span>$P^{1/2} \big(P^{-1/2} Q P^{-1/2}\big)^a P^{1/2}$</span></td></tr><tr><td>logdet0</td><td>uses weighted mean algorithm <a href="#PosDefManifold.logdet0Mean"><code>logdet0Mean</code></a></td></tr><tr><td>Jeffrey</td><td>uses weighted mean <a href="#Statistics.mean"><code>mean</code></a></td></tr><tr><td>VonNeumann</td><td>N.A.</td></tr><tr><td>Wasserstein</td><td><span>$b^2P+a^2Q +ab\big[(PQ)^{1/2} +(QP)^{1/2}\big]$</span></td></tr></table><p><strong>legend:</strong> <span>$L_X$</span>, <span>$S_X$</span> and <span>$D_X$</span>    are the Cholesky lower triangle of <span>$X$</span>, its strictly lower triangular part    and diagonal part, respectively (hence, <span>$S_X+D_X=L_X$</span>,  <span>$L_XL_X^*=X$</span>).</p><p><strong>See also</strong>: <a href="#Statistics.mean"><code>mean</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using PosDefManifold
P=randP(10)
Q=randP(10)
# Wasserstein mean
M=geodesic(Wasserstein, P, Q, 0.5)
# extrapolate suing the Fisher metric
E=geodesic(Fisher, P, Q, 2)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L82-L150">source</a></section><h2><a class="nav-anchor" id="Distances-1" href="#Distances-1">Distances</a></h2><table><tr><th>Function</th><th>Description</th></tr><tr><td><a href="#PosDefManifold.distanceSqr"><code>distanceSqr</code></a>, <code>distanceÂ²</code></td><td>Squared distance between positive definite matrices</td></tr><tr><td><a href="#PosDefManifold.distance"><code>distance</code></a></td><td>Distance between positive definite matrices</td></tr></table><p>â‹…</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.distanceSqr" href="#PosDefManifold.distanceSqr"><code>PosDefManifold.distanceSqr</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">(1) distanceSqr(metric::Metric, P::â„{T}) where T&lt;:RealOrComplex
(2) distanceSqr(metric::Metric, P::â„{T}, Q::â„{T}) where T&lt;:RealOrComplex
(3) distanceSqr(metric::Metric, D::ğ”»{S}) where S&lt;:Real
(4) distanceSqr(metric::Metric, D::ğ”»{S}, E::ğ”»{S}) where S&lt;:Real</code></pre><p><strong>alias</strong>: <code>distanceÂ²</code></p><p>(1) Return <span>$Î´^2(P, I)$</span>, the <em>square of the distance</em> (or <em>divergence</em>) of positive definite  matrix <span>$P$</span> from the the identity matrix. See <a href="../introToRiemannianGeometry/#distance-from-the-origin-1">distance from the origin</a>.</p><p>(2) Return <span>$Î´^2(P, Q)$</span>, the <em>square of the distance</em> (or <em>divergence</em>) between two  positive definite matrices <span>$P$</span> and <span>$Q$</span>. See <a href="../introToRiemannianGeometry/#distance-1">distance</a>.</p><p>In both cases the distance function <span>$Î´$</span> is induced by the argument <code>metric</code> of type  <a href="../MainModule/#Metric::Enumerated-type-1">Metric::Enumerated type</a>.</p><p><span>$P$</span> in (1) and <span>$P$</span>, <span>$Q$</span> in (2) must be flagged by julia as <code>Hermitian</code>.  See <a href="../MainModule/#typecasting-matrices-1">typecasting matrices</a>.</p><p>(3) and (4) are specialized methods of (1) and (2), respectively,  for real positive definite <code>Diagonal</code> matrices.  See <a href="../MainModule/#â„Vector-type-1">â„Vector type</a> and <a href="../MainModule/#ğ”»Vector-type-1">ğ”»Vector type</a>.</p><p><strong>Maths</strong></p><p>For point <span>$P$</span> the <em>squared distances from the identity</em>  for the supported metrics are:</p><table><tr><th>Metric</th><th>Squared Distance from the identity</th></tr><tr><td>Euclidean</td><td><span>$âˆ¥P-Iâˆ¥^2$</span></td></tr><tr><td>invEuclidean</td><td><span>$âˆ¥P^{-1}-Iâˆ¥^2$</span></td></tr><tr><td>ChoEuclidean</td><td><span>$âˆ¥L_P-Iâˆ¥^2$</span></td></tr><tr><td>logEuclidean</td><td><span>$âˆ¥\textrm{log}Pâˆ¥^2$</span></td></tr><tr><td>logCholesky</td><td><span>$âˆ¥S_Pâˆ¥^2+âˆ¥\textrm{log}D_Pâˆ¥^2$</span></td></tr><tr><td>Fisher</td><td><span>$âˆ¥\textrm{log}Pâˆ¥^2$</span></td></tr><tr><td>logdet0</td><td><span>$\textrm{logdet}\frac{1}{2}(P+I) - \frac{1}{2}\textrm{logdet}(P)$</span></td></tr><tr><td>Jeffrey</td><td><span>$\frac{1}{2}\textrm{tr}(P+P^{-1})-n$</span></td></tr><tr><td>VonNeumann</td><td><span>$\frac{1}{2}\textrm{tr}(P\textrm{log}P-\textrm{log}P)$</span></td></tr><tr><td>Wasserstein</td><td><span>$\textrm{tr}(P+I) -2\textrm{tr}(P^{1/2})$</span></td></tr></table><p>For points <span>$P$</span> and <span>$Q$</span> their <em>squared distances</em> for the supported metrics are:</p><table><tr><th>Metric</th><th>Squared Distance</th></tr><tr><td>Euclidean</td><td><span>$âˆ¥P-Qâˆ¥^2$</span></td></tr><tr><td>invEuclidean</td><td><span>$âˆ¥P^{-1}-Q^{-1}âˆ¥^2$</span></td></tr><tr><td>ChoEuclidean</td><td><span>$âˆ¥ L_P - L_Q âˆ¥^2$</span></td></tr><tr><td>logEuclidean</td><td><span>$âˆ¥\textrm{log}P-\textrm{log}Qâˆ¥^2$</span></td></tr><tr><td>logCholesky</td><td><span>$âˆ¥S_P-S_Qâˆ¥^2+âˆ¥\textrm{log}D_P-\textrm{log}D_Qâˆ¥^2$</span></td></tr><tr><td>Fisher</td><td><span>$âˆ¥\textrm{log}(P^{-1/2}QP^{-1/2})âˆ¥^2$</span></td></tr><tr><td>logdet0</td><td><span>$\textrm{logdet}\frac{1}{2}(P+Q) - \frac{1}{2}\textrm{logdet}(PQ)$</span></td></tr><tr><td>Jeffrey</td><td><span>$\frac{1}{2}\textrm{tr}(Q^{-1}P+P^{-1}Q)-n$</span></td></tr><tr><td>VonNeumann</td><td><span>$\frac{1}{2}\textrm{tr}(P\textrm{log}P-P\textrm{log}Q+Q\textrm{log}Q-Q\textrm{log}P)$</span></td></tr><tr><td>Wasserstein</td><td><span>$\textrm{tr}(P+Q) -2\textrm{tr}(P^{1/2}QP^{1/2})^{1/2}$</span></td></tr></table><p><strong>legend:</strong> <span>$L_X$</span>, <span>$S_X$</span> and <span>$D_X$</span>   are the Cholesky lower triangle of <span>$X$</span>, its strictly lower triangular part   and diagonal part, respectively (hence, <span>$S_X+D_X=L_X$</span>,  <span>$L_XL_X^*=X$</span>).</p><p><strong>See also</strong>: <a href="#PosDefManifold.distanceSqrMat"><code>distanceSqrMat</code></a>.</p><p><strong>Examples (1)</strong></p><pre><code class="language-none">using PosDefManifold
P=randP(10)
d=distanceSqr(Wasserstein, P)
e=distanceSqr(Fisher, P)
metric=Metric(Int(logdet0)) # or metric=logdet0
s=string(metric) # check what is the current metric
f=distanceÂ²(metric, P) #using the alias distanceÂ²</code></pre><p><strong>Examples (2)</strong></p><pre><code class="language-none">using PosDefManifold
P=randP(10)
Q=randP(10)
d=distanceSqr(logEuclidean, P, Q)
e=distanceÂ²(Jeffrey, P, Q)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L233-L313">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.distance" href="#PosDefManifold.distance"><code>PosDefManifold.distance</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">(1) distance(metric::Metric, P::â„{T}) where T&lt;:RealOrComplex
(2) distance(metric::Metric, P::â„{T}, Q::â„{T}) where T&lt;:RealOrComplex
(3) distance(metric::Metric, D::ğ”»{S}) where S&lt;:Real
(4) distance(metric::Metric, D::ğ”»{S}, E::ğ”»{S}) where S&lt;:Real</code></pre><p>(1) Return <span>$Î´(P, I)$</span>, the <em>distance</em> between positive definite matrix <span>$P$</span> and  the identity matrix.</p><p>(2) Return <span>$Î´(P, Q)$</span>, the <em>distance</em> between positive definite  matrices <span>$P$</span> and <span>$Q$</span>.</p><p>(3) and (4) are specialized methods of (1) and (2), respectively,  for real positive definite <code>Diagonal</code> matrices.</p><p>This is the square root of <a href="#PosDefManifold.distanceSqr"><code>distanceSqr</code></a>  and is invoked with the same syntax therein.</p><p><strong>See also</strong>: <a href="#PosDefManifold.distanceMat"><code>distanceMat</code></a>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L434-L453">source</a></section><h2><a class="nav-anchor" id="Graphs-and-Laplacians-1" href="#Graphs-and-Laplacians-1">Graphs and Laplacians</a></h2><table><tr><th>Function</th><th>Description</th></tr><tr><td><a href="#PosDefManifold.distanceSqrMat"><code>distanceSqrMat</code></a>, <code>distanceÂ²Mat</code></td><td>Lower triangular matrix of all squared inter-distances</td></tr><tr><td><a href="#PosDefManifold.distanceMat"><code>distanceMat</code></a></td><td>Lower triangular matrix of all inter-distances</td></tr><tr><td><a href="#PosDefManifold.laplacian"><code>laplacian</code></a></td><td>Laplacian of a squared inter-distances matrix</td></tr><tr><td><a href="#PosDefManifold.laplacianEigenMaps"><code>laplacianEigenMaps</code></a>, <code>laplacianEM</code></td><td>Eigen maps (eigenvectors) of a Laplacian</td></tr><tr><td><a href="#PosDefManifold.spectralEmbedding"><code>spectralEmbedding</code></a>, <code>spEmb</code></td><td>Spectral Embedding (the above functions run in series)</td></tr></table><p>â‹…</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.distanceSqrMat" href="#PosDefManifold.distanceSqrMat"><code>PosDefManifold.distanceSqrMat</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">    (1) distanceSqrMat(metric::Metric, ğ::â„Vector;
    &lt;â©=false&gt;)

    (2) distanceSqrMat(type::Type{T}, metric::Metric, ğ::â„Vector;
    &lt;â©=false&gt;) where T&lt;:AbstractFloat</code></pre><p><strong>alias</strong>: <code>distanceÂ²Mat</code></p><p>Given a 1d array <span>$ğ$</span> of <span>$k$</span> positive definite matrices  <span>${P_1,...,P_k}$</span> of <a href="../MainModule/#â„Vector-type-1">â„Vector type</a>, create the <span>$kâ‹…k$</span> real  <code>LowerTriangular</code> matrix comprising elements <span>$Î´^2(P_i, P_j)\textrm{, for all }i&gt;=j$</span>.</p><p>This is the lower triangular matrix holding all <em>squared inter-distances</em>  (zero on diagonal), using the  specified <code>metric</code>, of type <a href="../MainModule/#Metric::Enumerated-type-1">Metric::Enumerated type</a>,  giving rise to distance function <span>$Î´$</span>. See <a href="#PosDefManifold.distanceSqr"><code>distanceSqr</code></a>.</p><p>Only the lower triangular part is computed in order to optimize memory use.</p><p>By default, the result matrix is of type <code>Float32</code>. The type can be changed  to another real <code>type</code> using method (2).</p><p>&lt;optional keyword arguments&gt;:</p><ul><li>if â©=true the computation of inter-distances is multi-threaded.</li></ul><div class="admonition note"><div class="admonition-title">Nota Bene</div><div class="admonition-text"><p><a href="https://docs.julialang.org/en/v1/manual/parallel-computing/#Multi-Threading-(Experimental)-1">Multi-threading</a> is automatically disabled if the number of threads Julia is instructed to use is <span>$&lt;2$</span> or <span>$&lt;2k$</span>. See <a href="../MainModule/#Threads-1">Threads</a>.</p></div></div><p><strong>See</strong>: <a href="../introToRiemannianGeometry/#distance-1">distance</a>.</p><p><strong>See also</strong>: <a href="#PosDefManifold.laplacian"><code>laplacian</code></a>, <a href="#PosDefManifold.laplacianEigenMaps"><code>laplacianEigenMaps</code></a>, <a href="#PosDefManifold.spectralEmbedding"><code>spectralEmbedding</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using PosDefManifold
# Generate a set of 8 random 10x10 SPD matrices
Pset=randP(10, 8) # or, using unicode: ğ=randP(10, 8)
# Compute the squared inter-distance matrix according to the log Euclidean metric.
# This is much faster as compared to the Fisher metric and in general
# it is a good approximation.
Î”Â²=distanceSqrMat(logEuclidean, Pset)

# return a matrix of type Float64
Î”Â²64=distanceSqrMat(Float64, logEuclidean, Pset)

# Multi-threaded
Î”Â²=distanceSqrMat(Fisher, Pset; â©=true)

# Get the full matrix of inter-distances
fullÎ”Â²=Hermitian(Î”Â², :L)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L466-L521">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.distanceMat" href="#PosDefManifold.distanceMat"><code>PosDefManifold.distanceMat</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">    (1) distanceMat(metric::Metric, ğ::â„Vector;
    &lt;â©=true&gt;)

    (2) distanceMat(type::Type{T}, metric::Metric, ğ::â„Vector;
    &lt;â©=true&gt;) where T&lt;:AbstractFloat</code></pre><p>Given a 1d array <span>$ğ$</span> of <span>$k$</span> positive definite matrices  <span>${P_1,...,P_k}$</span> of <a href="../MainModule/#â„Vector-type-1">â„Vector type</a>, create the <span>$kâ‹…k$</span> real  <code>LowerTriangular</code> matrix comprising elements  <span>$Î´(P_i, P_j)\textrm{, for all }i&gt;=j$</span>.</p><p>This is the lower triangular matrix holding all <em>inter-distances</em>  (zero on diagonal), using the  specified <code>metric</code>, of type <a href="../MainModule/#Metric::Enumerated-type-1">Metric::Enumerated type</a>,  giving rise to distance <span>$Î´$</span>. See <a href="#PosDefManifold.distance"><code>distance</code></a>.</p><p>Only the lower triangular part is computed in order to optimize memory use.</p><p>By default, the result matrix is of type <code>Float32</code>. The type can be changed  to another real <code>type</code> using method (2).</p><p>The elements of this matrix are the square root of  <a href="#PosDefManifold.distanceSqrMat"><code>distanceSqrMat</code></a>.</p><p>&lt;optional keyword arguments&gt;:</p><ul><li>if â©=true the computation of inter-distances is multi-threaded.</li></ul><div class="admonition warning"><div class="admonition-title">Multi-Threading</div><div class="admonition-text"><p><a href="https://docs.julialang.org/en/v1/manual/parallel-computing/#Multi-Threading-(Experimental)-1">Multi-threading</a> is still experimental in julia. Multi-threading is automatically disabled if the number of threads Julia is instructed to use is <span>$&lt;2$</span> or <span>$&lt;4k$</span>. See <a href="../MainModule/#Threads-1">Threads</a>.</p></div></div><p><strong>See</strong>: <a href="../introToRiemannianGeometry/#distance-1">distance</a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using PosDefManifold
# Generate a set of 4 random 10x10 SPD matrices
Pset=randP(10, 4) # or, using unicode: ğ=randP(10, 4)
Î”=distanceMat(Fisher, Pset)

# return a matrix of type Float64
Î”64=distanceMat(Float64, Fisher, Pset)

# Multi-threaded
Î”64=distanceMat(Fisher, Pset; â©=true)

# Get the full matrix of inter-distances
fullÎ”=Hermitian(Î”, :L)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L626-L679">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.laplacian" href="#PosDefManifold.laplacian"><code>PosDefManifold.laplacian</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">laplacian(Î”Â²::ğ•ƒ{S}, epsilon::Real=0;
          &lt;densityInvariant=false&gt;) where S&lt;:Real</code></pre><p>Given a <code>LowerTriangular</code> matrix of squared inter-distances <span>$Î”^2$</span>,  return the lower triangular part of the so-called  <em>normalized Laplacian</em> or <em>density-invariant normalized Laplacian</em>,  which in both cases is a symmetric Laplacian.  The elements of the Laplacian are of the same type as the elements of <span>$Î”^2$</span>.  The result is a <code>LowerTriangular</code> matrix.</p><p>The definition of Laplacian given by Lafon (2004)<a href="../introToRiemannianGeometry/#-1">ğŸ“</a> is implemented:</p><p>First, a <a href="https://bit.ly/1HVyf55">Gaussian radial basis functions</a>,  known as <em>Gaussian kernel</em> or <em>heat kernel</em>,  is applied to all elements of <span>$Î”^2$</span>, such as</p><p><span>$W_{ij} = exp\bigg(\frac{\displaystyle{-Î”^2_{ij}}}{\displaystyle{2Îµ}}\bigg)$</span>,</p><p>where <span>$Îµ$</span> is the <em>bandwidth</em> of the kernel.</p><p>If &lt;optional keyword argument&gt; <code>densityInvariant=true</code> is used,   then the density-invariant transformation is applied</p><p><span>$W &lt;- E^{-1}WE^{-1}$</span></p><p>where <span>$E$</span> is the diagonal matrix holding on the main diagonal   the sum of the rows (or columns) of <span>$W$</span>.</p><p>Finally, the normalized Laplacian (density-invariant or not) is defined as</p><p><span>$Î© = D^{-1/2}WD^{-1/2}$</span>,</p><p>where <span>$D$</span> is the diagonal matrix holding on the main diagonal   the sum of the rows (or columns) of <span>$W$</span>.</p><p>If you do not provide argument <code>epsilon</code>, the bandwidth <span>$Îµ$</span> is set to the   median of the elements of squared distance matrix <span>$Î”^2_{ij}$</span>.   Another educated guess is the dimension of the original data, that is,   the data that has been used to compute the squared distance matrix.   For positive definite matrices this is <span>$n(n-1)/2$</span>, where <span>$n$</span> is the   dimension of the matrices. Still another is the dimension of the ensuing   <a href="#PosDefManifold.spectralEmbedding"><code>spectralEmbedding</code></a> space.   Keep in mind that by tuning the <code>epsilon</code> parameter   (which must be positive) you can control both the rate of compression of the   embedding space and the spread of points in the embedding space.   See Coifman et <em>al.</em> (2008)<a href="../introToRiemannianGeometry/#-1">ğŸ“</a> for a discussion on <span>$Îµ$</span>.</p><div class="admonition note"><div class="admonition-title">Nota Bene</div><div class="admonition-text"><p>The Laplacian as here defined can be requested for any input matrix of squared inter-distances, for example, those obtained on scalars or on vectors using appropriate metrics. In any case, only the lower triangular part of the Laplacian is taken as input. See <a href="../MainModule/#typecasting-matrices-1">typecasting matrices</a>.</p></div></div><p><strong>See also</strong>: <a href="#PosDefManifold.distanceSqrMat"><code>distanceSqrMat</code></a>, <a href="#PosDefManifold.laplacianEigenMaps"><code>laplacianEigenMaps</code></a>, <a href="#PosDefManifold.spectralEmbedding"><code>spectralEmbedding</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using PosDefManifold
# Generate a set of 4 random 10x10 SPD matrices
Pset=randP(10, 4) # or, using unicode: ğ=randP(10, 4)
Î”Â²=distanceSqrMat(Fisher, Pset)
Î©=laplacian(Î”Â²)

# density-invariant Laplacian
Î©=laplacian(Î”Â²; densityInvariant=true)

# increase the bandwidth
r=size(Î”Â², 1)
myÎµFactor=0.1
med=Statistics.median([Î”Â²[i, j] for j=1:r-1 for i=j+1:r])
Îµ=2*myÎµFactor*med
Î©=laplacian(Î”Â², Îµ; densityInvariant=true)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L689-L763">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.laplacianEigenMaps" href="#PosDefManifold.laplacianEigenMaps"><code>PosDefManifold.laplacianEigenMaps</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">    laplacianEigenMaps(Î©::ğ•ƒ{S}, q::Int;
    &lt;
    tol::Real=0,
    maxiter::Int=300,
    â°=false &gt;) where S&lt;:Real</code></pre><p><strong>alias</strong>: <code>laplacianEM</code></p><p>Given the lower triangular part of a Laplacian <span>$Î©$</span>  (see <a href="#PosDefManifold.laplacian"><code>laplacian</code></a> ) return the <em>eigen maps</em> in <span>$q$</span> dimensions,  i.e., the <span>$q$</span> eigenvectors of the Laplacian associated with the largest <span>$q$</span>  eigenvalues, excluding the first (which is always equal to 1.0).  The eigenvectors are of the same type as <span>$Î©$</span>. They are all divided  element-wise by the first eigenvector (see Lafon, 2004<a href="../introToRiemannianGeometry/#-1">ğŸ“</a>).</p><p>The eigenvectors of the Laplacian are computed by the  power iterations+modified Gram-Schmidt method (see <a href="../linearAlgebra/#PosDefManifold.powerIterations"><code>powerIterations</code></a>),  allowing the execution of this function for Laplacian matrices of very large size.</p><p>Return the 4-tuple <span>$(Î›, U, iterations, convergence)$</span>, where:</p><ul><li><span>$Î›$</span> is a <span>$qâ‹…q$</span> diagonal matrix holding on diagonal the eigenvalues corresponding to the <span>$q$</span> dimensions of the Laplacian eigen maps,</li><li><span>$U$</span> holds in columns the <span>$q$</span> eigenvectors holding the <span>$q$</span> coordinates of the points in the embedding space,</li><li><span>$iterations$</span> is the number of iterations executed by the power method,</li><li><span>$convergence$</span> is the convergence attained by the power method.</li></ul><p>Using the notion of Laplacian, spectral embedding seek a  low-dimension representation of the data emphasizing local neighbothood  information while neglecting long-distance information.  The embedding is non-linear, however the embedding space is Euclidean.  The eigenvectors of <span>$U$</span> holds the coordinates of the points in the  embedding space (typically two- or three-dimensional for plotting or more  for clustering). Spectral embedding is done for plotting data in low-dimension,  clustering, imaging, classification, following their trajectories over time  or other dimensions, and much more.  For examples of applications see Ridrigues et <em>al.</em> (2018) <a href="../introToRiemannianGeometry/#-1">ğŸ“</a>  and references therein.</p><p><strong>Arguments</strong>:</p><ul><li><span>$Î©$</span> is a real <code>LowerTriangular</code> normalized Laplacian obtained by the <a href="#PosDefManifold.laplacian"><code>laplacian</code></a> function,</li><li><span>$q$</span> is the dimension of the Laplacian eigen maps;</li><li>The following are <em>&lt;optional keyword arguments&gt;</em> for the power iterations:<ul><li><code>tol</code> is the tolerance for convergence (see below),</li><li><code>maxiter</code> is the maximum number of iterations allowed,</li><li>if <code>â°</code> is true, the convergence at all iterations will be printed.</li></ul></li></ul><div class="admonition note"><div class="admonition-title">Nota Bene</div><div class="admonition-text"><p>The maximum value of <span>$q$</span> that can be requested is <span>$n-1$</span>, where <span>$n$</span> is the size of the Laplacian. In general, <span>$q=2$</span> or <span>$q=3$</span> is requested.</p><p><span>$tol$</span> defaults to the square root of <code>Base.eps</code> of the (real) type of <span>$Î©$</span>. This corresponds to requiring equality for the convergence criterion over two successive power iterations of about half of the significant digits.</p></div></div><p><strong>See also</strong>: <a href="#PosDefManifold.distanceSqrMat"><code>distanceSqrMat</code></a>, <a href="#PosDefManifold.laplacian"><code>laplacian</code></a>, <a href="#PosDefManifold.spectralEmbedding"><code>spectralEmbedding</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using PosDefManifold
# Generate a set of 4 random 10x10 SPD matrices
Pset=randP(10, 4)
Î”Â²=distanceSqrMat(Fisher, Pset)
Î©=laplacian(Î”Â²)
evalues, maps, iterations, convergence=laplacianEM(Î©, 2)
evalues, maps, iterations, convergence=laplacianEM(Î©, 2; â°=true)
evalues, maps, iterations, convergence=laplacianEM(Î©, 2; â°=true, maxiter=500)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L795-L864">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.spectralEmbedding" href="#PosDefManifold.spectralEmbedding"><code>PosDefManifold.spectralEmbedding</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">    (1) spectralEmbedding(metric::Metric, ğ::â„Vector, q::Int, epsilon::Real=0;
    &lt;
    tol::Real=0,
    maxiter::Int=300,
    densityInvariant=false,
    â°=false,
    â©=false &gt;)

    (2) spectralEmbedding(type::Type{T}, metric::Metric, ğ::â„Vector, q::Int, epsilon::Real=0;
    &lt; same optional keyword arguments as in (1) &gt;) where T&lt;:Real</code></pre><p><strong>alias</strong>: <code>spEmb</code></p><p>Given a 1d array <span>$ğ$</span> of <span>$k$</span> positive definite matrices <span>${P_1,...,P_k}$</span>  (real or complex), compute its <em>eigen maps</em> in <span>$q$</span> dimensions.</p><p>This function runs one after the other the functions:</p><ul><li><a href="#PosDefManifold.distanceSqrMat"><code>distanceSqrMat</code></a> (compute the squared inter-distance matrix),</li><li><a href="#PosDefManifold.laplacian"><code>laplacian</code></a> (compute the normalized Laplacian),</li><li><a href="#PosDefManifold.laplacianEigenMaps"><code>laplacianEigenMaps</code></a> (get the eigen maps).</li></ul><p>By default all computations above are done with <code>Float32</code> precision.  Another real type can be requested using method (2), where the <code>type</code> argument  is defined.</p><p>Return the 4-tuple <code>(Î›, U, iterations, convergence)</code>, where:</p><ul><li><span>$Î›$</span> is a <span>$qâ‹…q$</span> diagonal matrix holding on diagonal the eigenvalues corresponding to the <span>$q$</span> dimensions of the Laplacian eigen maps,</li><li><span>$U$</span> holds in columns the <span>$q$</span> eigenvectors holding the <span>$q$</span> coordinates of the points in the embedding space,</li><li><span>$iterations$</span> is the number of iterations executed by the power method,</li><li><span>$convergence$</span> is the convergence attained by the power method.</li></ul><p><strong>Arguments</strong>:</p><ul><li><code>metric</code> is the metric of type <a href="../MainModule/#Metric::Enumerated-type-1">Metric::Enumerated type</a> used for computing the inter-distances,</li><li><span>$ğ$</span> is a 1d array of <span>$k$</span> positive matrices of <a href="../MainModule/#â„Vector-type-1">â„Vector type</a>,</li><li><span>$q$</span> is the dimension of the Laplacian eigen maps,</li><li><span>$epsilon$</span> is the bandwidth of the Laplacian (see <a href="#PosDefManifold.laplacian"><code>laplacian</code></a>);</li><li>The following <em>&lt;optional keyword argument&gt;</em> applyies for computing the inter-distances:<ul><li>if <code>â©=true</code> the computation of inter-distances is multi-threaded.</li></ul></li><li>The following <em>&lt;optional keyword argument&gt;</em> applyies to the computation of the Laplacian by the <a href="#PosDefManifold.laplacian"><code>laplacian</code></a> function:<ul><li>if <code>densityInvariant=true</code> the density-invariant Laplacian is computed (see <a href="#PosDefManifold.laplacian"><code>laplacian</code></a>).</li></ul></li><li>The following are <em>&lt;optional keyword arguments&gt;</em> for the power method iterative algorithm invoked by <a href="#PosDefManifold.laplacianEigenMaps"><code>laplacianEigenMaps</code></a>:<ul><li><code>tol</code> is the tolerance for convergence of the power method (see below),</li><li><code>maxiter</code> is the maximum number of iterations allowed for the power method,</li><li>if <code>â°=true</code> the convergence at all iterations will be printed;</li></ul></li></ul><div class="admonition note"><div class="admonition-title">Nota Bene</div><div class="admonition-text"><p><span>$tol$</span> defaults to the square root of <code>Base.eps</code> of the <code>Float32</code> type (1) or of the <code>type</code> passed as argumant (2). This corresponds to requiring equality for the convergence criterion over two successive power iterations of about half of the significant digits.</p><p><a href="https://docs.julialang.org/en/v1/manual/parallel-computing/#Multi-Threading-(Experimental)-1">Multi-threading</a> is automatically disabled if the number of threads Julia is instructed to use is <span>$&lt;2$</span> or <span>$&lt;2k$</span>. See <a href="../MainModule/#Threads-1">Threads</a>.</p></div></div><p><strong>See also</strong>: <a href="#PosDefManifold.distanceSqrMat"><code>distanceSqrMat</code></a>, <a href="#PosDefManifold.laplacian"><code>laplacian</code></a>, <a href="#PosDefManifold.laplacianEigenMaps"><code>laplacianEigenMaps</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using PosDefManifold
# Generate a set of k random 10x10 SPD matrices
k=10
Pset=randP(10, k)
evalues, maps, iter, conv=spectralEmbedding(Fisher, Pset, 2)

# show convergence information
evalues, maps, iter, conv=spectralEmbedding(Fisher, Pset, 2; â°=true)

# use Float64 precision.
evalues, maps, iter, conv=spectralEmbedding(Float64, Fisher, Pset, 2)

# Multi-threaded
evalues, maps, iter, conv=spectralEmbedding(Fisher, Pset, k-1; â°=true, â©=true)

using Plots
# check eigevalues and eigenvectors
plot(diag(evalues))
plot(maps[:, 1])
plot!(maps[:, 2])
plot!(maps[:, 3])

# plot the data in the embedded space
plot(maps[:, 1], maps[:, 2], seriestype=:scatter, title=&quot;Spectral Embedding&quot;, label=&quot;Pset&quot;)

# try a different value of epsilon
evalues, maps, iter, conv=spEmb(Fisher, Pset, k-1, 0.01; â©=true, maxiter=1000)
plot(maps[:, 1], maps[:, 2], seriestype=:scatter, title=&quot;Spectral Embedding&quot;, label=&quot;Pset&quot;)
# see the example in `Laplacian function for more on this`</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L882-L974">source</a></section><h2><a class="nav-anchor" id="Means-1" href="#Means-1">Means</a></h2><table><tr><th>Function</th><th>Description</th></tr><tr><td><a href="#Statistics.mean"><code>mean</code></a></td><td>Weighted FrÃ©chet mean (wFm) of a scalar or matrix set using any metric</td></tr><tr><td><a href="#PosDefManifold.means"><code>means</code></a></td><td>As above for several sets at once</td></tr><tr><td><a href="#PosDefManifold.generalizedMean"><code>generalizedMean</code></a></td><td>Generalized wFm of a matrix set</td></tr><tr><td><a href="#PosDefManifold.geometricMean"><code>geometricMean</code></a>, <code>gMean</code></td><td>wFm of a matrix set minimizing the dispersion according to the Fisher metric (iterative)</td></tr><tr><td><a href="#PosDefManifold.geometricpMean"><code>geometricpMean</code></a>, <code>gpMean</code></td><td>robust wFm of a matrix set minimizing the p-dispersion according to the Fisher metric (iterative)</td></tr><tr><td><a href="#PosDefManifold.logdet0Mean"><code>logdet0Mean</code></a>, <code>ld0Mean</code></td><td>wFm of a matrix set according to the logdet0 metric (iterative)</td></tr><tr><td><a href="#PosDefManifold.wasMean"><code>wasMean</code></a></td><td>wFm of a matrix set according to the Wasserstein metric (iterative)</td></tr><tr><td><a href="#PosDefManifold.powerMean"><code>powerMean</code></a></td><td>Power wFm of a matrix set (iterative)</td></tr></table><p>â‹…</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Statistics.mean" href="#Statistics.mean"><code>Statistics.mean</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">    (1) mean(metric::Metric, P::â„{T}, Q::â„{T}) where T&lt;:RealOrComplex

    (2) mean(metric::Metric, D::ğ”»{T}, E::ğ”»{T}) where T&lt;:Real

    (3) mean(metric::Metric, ğ::â„Vector;
    &lt;
    w::Vector=[],
    âœ“w=true,
    â°=false,
    â©=false &gt;)

    (4) mean(metric::Metric, ğƒ::ğ”»Vector;
    &lt; same optional keyword arguments as in (3) &gt;)</code></pre><p>(1) Mean of two positive definite matrices, passed in arbitrary order as  arguments <span>$P$</span> and <span>$Q$</span>, using the specified <code>metric</code> of type  <a href="../MainModule/#Metric::Enumerated-type-1">Metric::Enumerated type</a>. The order is arbitrary as all metrics  implemented in <strong>PosDefManifold</strong> are symmetric.  This is the midpoint of the geodesic.  For the weighted mean of two positive definite matrices use instead  the <a href="#PosDefManifold.geodesic"><code>geodesic</code></a> function.  <span>$P$</span> and <span>$Q$</span> must be flagged as <code>Hermitian</code>. See <a href="../MainModule/#typecasting-matrices-1">typecasting matrices</a>.</p><p>(2) Like in (1), but for two real diagonal positive definite matrices  <span>$D$</span> and <span>$E$</span>.</p><p>(3) <a href="../introToRiemannianGeometry/#FrÃ©chet-mean-1">FrÃ©chet mean</a> of an 1d array <span>$ğ$</span> of <span>$k$</span> positive definite  matrices <span>$ğ={P_1,...,P_k}$</span> of <a href="../MainModule/#â„Vector-type-1">â„Vector type</a>,  with optional non-negative real weights <span>$w={w_1,...,w_k}$</span> and using the  specified <code>metric</code>as in (1).</p><p>(5) <a href="../introToRiemannianGeometry/#FrÃ©chet-mean-1">FrÃ©chet mean</a> of an 1d array <span>$ğƒ$</span> of <span>$k$</span> positive definite  matrices <span>$ğƒ={D_1,...,D_k}$</span> of <a href="../MainModule/#ğ”»Vector-type-1">ğ”»Vector type</a>,  with optional non-negative real weights <span>$w={w_1,...,w_k}$</span> and using the  specified <code>metric</code>as in (1).</p><p>If you don&#39;t pass a weight vector with <em>&lt;optional keyword argument&gt;</em> <span>$w$</span>,  return the <em>unweighted mean</em>.</p><p>If <em>&lt;optional keyword argument&gt;</em> <code>âœ“w=true</code> (default), the weights are  normalized so as to sum up to 1, otherwise they are used as they are passed  and should be already normalized.  This option is provided to allow  calling this function repeatedly without normalizing the same weights  vector each time.</p><p>Adopting the <code>Fisher</code>, <code>logdet0</code> and <code>Wasserstein</code> metric in (3) and the  <code>logdet0</code> metric in (4), the mean is computed by means of an iterative  algorithm and information on its convergence is displayed in the REPL.  For suppressing this information and for more options for computing these means  call directly functions <a href="#PosDefManifold.geometricMean"><code>geometricMean</code></a>, <a href="#PosDefManifold.logdet0Mean"><code>logdet0Mean</code></a>  and <a href="#PosDefManifold.wasMean"><code>wasMean</code></a>. See also the robust function <a href="#PosDefManifold.geometricpMean"><code>geometricpMean</code></a>.</p><p>For (3) and (4), if <code>â©=true</code> is passed as <em>&lt;optional keyword argument&gt;</em>,  the computation of the mean is multi-threaded.</p><p>For (3) and (4), if <code>â°=true</code> and the mean is found by an itartive algorithm,  the covergence attained at each iteration is printed. Other information  such as if the algorithm has diverged is printed.</p><div class="admonition warning"><div class="admonition-title">Multi-Threading</div><div class="admonition-text"><p><a href="https://docs.julialang.org/en/v1/manual/parallel-computing/#Multi-Threading-(Experimental)-1">Multi-threading</a> is still experimental in julia. Multi-threading is automatically disabled if the number of threads Julia is instructed to use is <span>$&lt;2$</span> or <span>$&lt;4k$</span>. See <a href="../MainModule/#Threads-1">Threads</a>.</p></div></div><p><strong>Math</strong></p><p>The FrÃ©chet mean of a set of <span>$k$</span> matrices <span>${P_1, P_2,..., P_k}$</span> weighted by  <span>${w_1, w_2,..., w_k}:\sum_{i=1}^{k}w_i=1$</span> for the supported metrics are,  for those with closed form expression:</p><table><tr><th>Metric</th><th>weighted FrÃ©chet mean</th></tr><tr><td>Euclidean</td><td><span>$\sum_{i=1}^{k}w_i P_i$</span></td></tr><tr><td>invEuclidean</td><td><span>$\big(\sum_{i=1}^{k}w_i P_i^{-1}\big)^{-1}$</span></td></tr><tr><td>ChoEuclidean</td><td><span>$TT^*$</span>, where <span>$T=bL_P + aL_Q$</span></td></tr><tr><td>logEuclidean</td><td><span>$\textrm{exp}\big(\sum_{i=1}^{k}w_i\hspace{1pt} \textrm{log}P_i \big)$</span></td></tr><tr><td>logCholesky</td><td><span>$TT^*$</span>, where <span>$T=\sum_{i=1}^{k}(w_kS_k)+\sum_{i=1}^{k}(w_k\textrm{log}D_k)$</span></td></tr><tr><td>Jeffrey</td><td><span>$A^{1/2}\big(A^{-1/2}HA^{-1/2}\big)^{1/2}A^{1/2}$</span></td></tr></table><p>and for those that are found by an iterative algorithm and that verify an equation:</p><table><tr><th>Metric</th><th>equation verified by the weighted FrÃ©chet mean</th></tr><tr><td>Fisher</td><td><span>$\sum_{i=1}^{k}w_i\textrm{log}\big(G^{-1/2} P_k G^{-1/2}\big)=0.$</span></td></tr><tr><td>logdet0</td><td><span>$\sum_{i=1}^{k}w_i\big(\frac{1}{2}P_i+\frac{1}{2}G\big)^{-1}=G^{-1}$</span></td></tr><tr><td>VonNeumann</td><td>N.A.</td></tr><tr><td>Wasserstein</td><td><span>$G=\sum_{i=1}^{k}w_i\big( G^{1/2}  P_i G^{1/2}\big)^{1/2}$</span></td></tr></table><p><strong>legend:</strong> <span>$L_X$</span>, <span>$S_X$</span> and <span>$D_X$</span>   are the Cholesky lower triangle of <span>$X$</span>, its strictly lower triangular part   and diagonal part, respectively (hence, <span>$S_X+D_X=L_X$</span>,  <span>$L_XL_X^*=X$</span>).   <span>$A$</span> and <span>$H$</span> are the weighted arithmetic and weighted harmonic mean, respectively.</p><p><strong>See</strong>: <a href="../introToRiemannianGeometry/#geodesic-1">geodesic</a>, <a href="../introToRiemannianGeometry/#mean-1">mean</a>, <a href="../introToRiemannianGeometry/#FrÃ©chet-mean-1">FrÃ©chet mean</a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using LinearAlgebra, Statistics, PosDefManifold
# Generate 2 random 3x3 SPD matrices
P=randP(3)
Q=randP(3)
M=mean(logdet0, P, Q) # (1)
M=mean(Euclidean, P, Q) # (1)

# passing several matrices and associated weights listing them
# weights vector, does not need to be normalized
R=randP(3)
mean(Fisher, â„Vector([P, Q, R]); w=[1, 2, 3])

# Generate a set of 4 random 3x3 SPD matrices
Pset=randP(3, 4)
weights=[1, 2, 3, 1]
# passing a vector of Hermitian matrices (â„Vector type)
M=mean(Euclidean, Pset; w=weights) # (2) weighted Euclidean mean
M=mean(Wasserstein, Pset)  # (2) unweighted Wassertein mean
# display convergence information when using an iterative algorithm
M=mean(Fisher, Pset; â°=true)

# run multi-threaded when the number of matrices is high
using BenchmarkTools
Pset=randP(20, 160)
@benchmark(mean(logEuclidean, Pset)) # single-threaded
@benchmark(mean(logEuclidean, Pset; â©=true)) # multi-threaded</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L1011-L1138">source</a><div><div><pre><code class="language-none">mean(metric::Metric, Î½::Vector{T}) where T&lt;:RealOrComplex</code></pre><p>Mean of <span>$k$</span> real or complex scalars, using the specified <code>metric</code>  of type <a href="../MainModule/#Metric::Enumerated-type-1">Metric::Enumerated type</a>. Note that using the Fisher,  logEuclidean and Jeffrey metric, the resulting mean  is the scalar geometric mean. Note also that the code of this method  is in unit <em>statistics.jl</em>, while the code for all the others is  in unit <em>riemannianGeometry.jl</em>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using PosDefManifold
# Generate 10 random numbers distributed as a chi-square with 2 df.
Î½=[randÏ‡Â²(2) for i=1:10]
arithmetic_mean=mean(Euclidean, Î½)
geometric_mean=mean(Fisher, Î½)
harmonic_mean=mean(invEuclidean, Î½)
harmonic_mean&lt;=geometric_mean&lt;=arithmetic_mean # AGH inequality</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/statistics.jl#L48-L67">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.means" href="#PosDefManifold.means"><code>PosDefManifold.means</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">    (1) means(metric::Metric, ğ’«::â„Vectorâ‚‚;
    &lt;â©=false&gt;)

    (2) means(metric::Metric, ğ’Ÿ::ğ”»Vectorâ‚‚;
    &lt;â©=false&gt;)</code></pre><p>(1) Given a 2d array <span>$ğ’«$</span> of positive definite matrices as an <a href="../MainModule/#â„Vector-type-1">â„Vectorâ‚‚ type</a>  compute the <a href="../introToRiemannianGeometry/#FrÃ©chet-mean-1">FrÃ©chet mean</a> for as many <a href="../MainModule/#â„Vector-type-1">â„Vector type</a> objects  as hold in <span>$ğ’«$</span>, using the specified <code>metric</code> of type  <a href="../MainModule/#Metric::Enumerated-type-1">Metric::Enumerated type</a>.  Return the means in a vector of <code>Hermitian</code> matrices, that is, as an <code>â„Vector</code> type.</p><p>(2) Given a 2d array <span>$ğ’Ÿ$</span> of real positive definite matrices as an <a href="../MainModule/#ğ”»Vector-type-1">ğ”»Vectorâ‚‚ type</a>  compute the <a href="../introToRiemannianGeometry/#FrÃ©chet-mean-1">FrÃ©chet mean</a> for as many <a href="../MainModule/#ğ”»Vector-type-1">ğ”»Vector type</a> objects  as hold in <span>$ğ’Ÿ$</span>, using the specified <code>metric</code> of type  <a href="../MainModule/#Metric::Enumerated-type-1">Metric::Enumerated type</a>.  Return the means in a vector of <code>Diagonal</code> matrices, that is, as a <code>ğ”»Vector</code> type.</p><p>The weigted FrÃ©chet mean is not supported in this function.</p><p>If <em>&lt;optional key argmuent&gt;</em> â©=true the computation of the means  is multi-threaded.</p><div class="admonition warning"><div class="admonition-title">Multi-Threading</div><div class="admonition-text"><p><a href="https://docs.julialang.org/en/v1/manual/parallel-computing/#Multi-Threading-(Experimental)-1">Multi-threading</a> is still experimental in julia. For each mean to be computed, multi-threading is automatically disabled if the number of threads Julia is instructed to use is <span>$&lt;2$</span> or <span>$&lt;4k$</span>, where <span>$k$</span> is the number of matrices for which the mean is to be computed. See <a href="../MainModule/#Threads-1">Threads</a>.</p></div></div><p><strong>See also</strong>: <a href="#Statistics.mean"><code>mean</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-none"> using PosDefManifold
 # Generate a set of 4 random 3x3 SPD matrices
 Pset=randP(3, 4) # or, using unicode: ğ=randP(3, 4)
 # Generate a set of 40 random 4x4 SPD matrices
 Qset=randP(3, 40) # or, using unicode: ğ=randP(3, 40)
 # listing directly â„Vector objects
 means(logEuclidean, â„Vectorâ‚‚([Pset, Qset])) # or: means(logEuclidean, â„Vectorâ‚‚([ğ, ğ]))
 # note that [ğ, ğ] is actually a â„Vectorâ‚‚ type object

 # creating and passing an object of â„Vectorâ‚‚ type
 sets=â„Vectorâ‚‚(undef, 2) # or: ğ’«=â„Vectorâ‚‚(undef, 2)
 sets[1]=Pset # or: ğ’«[1]=ğ
 sets[2]=Qset # or: ğ’«[2]=ğ
 means(logEuclidean, sets) # or: means(logEuclidean, ğ’«)

 # going multi-threated

 # first, create 20 sets of 200 50x50 SPD matrices
 sets=â„Vectorâ‚‚([randP(50, 200) for i=1:20])

 # How much computing time we save ?
 # (example min time obtained with 4 threads &amp; 4 BLAS threads)
 using BenchmarkTools

 # non multi-threaded, mean with closed-form solution
 @benchmark(means(logEuclidean, sets)) # (6.196 s)

 # multi-threaded, mean with closed-form solution
 @benchmark(means(logEuclidean, sets; â©=true)) # (1.897 s)

 sets=â„Vectorâ‚‚([randP(10, 200) for i=1:10])

 # non multi-threaded, mean with iterative solution
 # wait a bit
 @benchmark(means(Fisher, sets)) # (4.672 s )

 # multi-threaded, mean with iterative solution
 @benchmark(means(Fisher, sets; â©=true)) # (1.510 s)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L1301-L1376">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.generalizedMean" href="#PosDefManifold.generalizedMean"><code>PosDefManifold.generalizedMean</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">    generalizedMean(ğ::Union{â„Vector, ğ”»Vector}, p::Real;
    &lt;
    w::Vector=[],
    âœ“w=true,
    â©=false &gt;)</code></pre><p>Given a 1d array <span>$ğ={P_1,...,P_k}$</span> of <span>$k$</span> positive definite matrices of  <a href="../MainModule/#â„Vector-type-1">â„Vector type</a> or real positive definite diagonal matrices of  <a href="../MainModule/#ğ”»Vector-type-1">ğ”»Vector type</a> and optional non-negative real weights vector  <span>$w={w_1,...,w_k}$</span>, return the <em>weighted generalized means</em> <span>$G$</span>  with real parameter <span>$p$</span>, that is,</p><p><span>$G=\big(\sum_{i=1}^{k}w_iP_i^p\big)^{1/p}$</span>.</p><p>If you don&#39;t pass a weight vector with <em>&lt;optional keyword argument&gt;</em> <span>$w$</span>,  return the <em>unweighted generalized mean</em></p><p><span>$G=\big(\sum_{i=1}^{k}P_i^p\big)^{1/p}$</span>.</p><p>If <em>&lt;optional keyword argument&gt;</em> <code>âœ“w=true</code> (default), the weights are  normalized so as to sum up to 1, otherwise they are used as they are passed  and should be already normalized.  This option is provided to allow  calling this function repeatedly without normalizing the weights each time.</p><p>If <em>&lt;optional key argmuent&gt;</em> â©=true the computation of the generalized mean  is multi-threaded.</p><div class="admonition warning"><div class="admonition-title">Multi-Threading</div><div class="admonition-text"><p><a href="https://docs.julialang.org/en/v1/manual/parallel-computing/#Multi-Threading-(Experimental)-1">Multi-threading</a> is still experimental in julia. Multi-threading is automatically disabled if the number of threads Julia is instructed to use is <span>$&lt;2$</span> or <span>$&lt;4k$</span>. See <a href="../MainModule/#Threads-1">Threads</a>.</p></div></div><p>The following special cases for parameter <span>$p$</span> are noteworthy:</p><ul><li>For <span>$p=\frac{1}{2}$</span> the generalized mean is the <a href="../introToRiemannianGeometry/#modified-Bhattacharyya-mean-1">modified Bhattacharyya mean</a>.</li><li>For <span>$p=1$</span> the generalized mean is the <a href="../introToRiemannianGeometry/#Euclidean-1">Euclidean</a> mean.</li><li>For <span>$p=-1$</span> the generalized mean is the <a href="../introToRiemannianGeometry/#inverse-Euclidean-1">inverse Euclidean</a> mean.</li><li>For (the limit of) <span>$p=0$</span> the generalized mean is the <a href="../introToRiemannianGeometry/#log-Euclidean-1">log Euclidean</a> mean, which is the <a href="../introToRiemannianGeometry/#Fisher-1">Fisher</a> mean when matrices in ğ all pair-wise commute.</li></ul><p>Notice that when matrices in ğ all pair-wise commute, for instance if the  matrices are diagonal,  the generalized means coincide with the <a href="../introToRiemannianGeometry/#power-means-1">power means</a>  for any <span>$pâˆˆ[-1, 1]$</span> and for <span>$p=0.5$</span> it coincides also with the  <a href="../introToRiemannianGeometry/#Wasserstein-1">Wasserstein</a> mean. For this reason the generalized means are used  as default initialization of both the <a href="#PosDefManifold.powerMean"><code>powerMean</code></a> and <a href="#PosDefManifold.wasMean"><code>wasMean</code></a>  algorithm.</p><p><strong>See</strong>: <a href="../introToRiemannianGeometry/#generalized-means-1">generalized means</a>.</p><p><strong>See also</strong>: <a href="#PosDefManifold.powerMean"><code>powerMean</code></a>, <a href="#PosDefManifold.wasMean"><code>wasMean</code></a>, <a href="#Statistics.mean"><code>mean</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using LinearAlgebra, Statistics, PosDefManifold
# Generate a set of 4 random 3x3 SPD matrices
Pset=randP(3, 4) # or, using unicode: ğ=randP(3, 4)

# weights vector, does not need to be normalized
weights=[1, 2, 3, 1]

# unweighted mean
G = generalizedMean(Pset, 0.25) # or: G = generalizedMean(ğ, 0.25)

# weighted mean
G = generalizedMean(Pset, 0.5; w=weights)

# with weights previously normalized we can set âœ“w=false
weights=weights./sum(weights)
G = generalizedMean(Pset, 0.5; w=weights, âœ“w=false)

# run multi-threaded when the number of matrices is high
using BenchmarkTools
Pset=randP(20, 160)
@benchmark(generalizedMean(Pset)) # single-threaded
@benchmark(generalizedMean(Pset; â©=true)) # multi-threaded</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L1385-L1465">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.geometricMean" href="#PosDefManifold.geometricMean"><code>PosDefManifold.geometricMean</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">    geometricMean(ğ::Union{â„Vector, ğ”»Vector};
    &lt;
    w::Vector=[],
    âœ“w=true,
    init=nothing,
    tol::Real=0,
    maxiter::Int=500,
    adaptStepSize=true,
    â°=false,
    â©=false &gt;)</code></pre><p><strong>alias</strong>: <code>gmean</code></p><p>Given a 1d array <span>$ğ={P_1,...,P_k}$</span> of <span>$k$</span> positive definite matrices of  <a href="../MainModule/#â„Vector-type-1">â„Vector type</a> or diagonal matrices of <a href="../MainModule/#ğ”»Vector-type-1">ğ”»Vector type</a>  and optional non-negative real weights vector <span>$w={w_1,...,w_k}$</span>,  return the 3-tuple <span>$(G, iter, conv)$</span>, where <span>$G$</span> is the mean according  to the <a href="../introToRiemannianGeometry/#Fisher-1">Fisher</a> metric and <span>$iter$</span>, <span>$conv$</span> are the number of iterations  and convergence attained by the algorithm.  Mean <span>$G$</span> is the unique positive definite matrix satisfying</p><p><span>$\sum_{i=1}^{k}w_i\textrm{log}\big(G^{-1/2} P_i G^{-1/2}\big)=0.$</span></p><p>For estimating it, this function implements the well-known gradient descent  algorithm, but with an exponential decaying step size <span>$Ï‚$</span>, yielding iterations</p><p><span>$G â†G^{1/2}\textrm{exp}\big(Ï‚\sum_{i=1}^{k}w_i\textrm{log}(G^{-1/2} P_i G^{-1/2})\big)G^{1/2}.$</span></p><p>If you don&#39;t pass a weight vector with <em>&lt;optional keyword argument&gt;</em> <span>$w$</span>,  return the <em>unweighted geometric mean</em>.</p><p>If <em>&lt;optional keyword argument&gt;</em> <code>âœ“w=true</code> (default), the weights are  normalized so as to sum up to 1, otherwise they are used as they are passed  and should be already normalized.  This option is provided to allow  calling this function repeatedly without normalizing the same weights  vector each time.</p><p>The following are more <em>&lt;optional keyword arguments</em>&gt;:</p><ul><li><code>init</code> is a matrix to be used as initialization for the mean. If no matrix is provided, the <a href="../introToRiemannianGeometry/#log-Euclidean-1">log Euclidean</a> mean will be used,</li><li><code>tol</code> is the tolerance for the convergence (see below).</li><li><code>maxiter</code> is the maximum number of iterations allowed</li><li>if <code>â°</code>=true, the convergence attained at each iteration and the step size <span>$Ï‚$</span> is printed. Also, a <em>warning</em> is printed if convergence is not attained.</li><li>if â©=true the iterations are multi-threaded (see below).</li><li>if <code>adaptStepSize</code>=false the step size <code>Ï‚</code> is fixed to 1 at all iterations.</li></ul><p>If the input is a 1d array of <span>$k$</span> real positive definite diagonal matrices  the solution is available in closed-form as the log Euclidean  mean, hence the <em>&lt;optional keyword arguments</em>&gt; <code>init</code>, <code>tol</code> and <code>â°</code>  have no effect and return the 3-tuple <span>$(G, 1, 0)$</span>.  See the <a href="../introToRiemannianGeometry/#log-Euclidean-1">log Euclidean</a> metric.</p><div class="admonition warning"><div class="admonition-title">Multi-Threading</div><div class="admonition-text"><p><a href="https://docs.julialang.org/en/v1/manual/parallel-computing/#Multi-Threading-(Experimental)-1">Multi-threading</a> is still experimental in julia. Multi-threading is automatically disabled if the number of threads Julia is instructed to use is <span>$&lt;2$</span> or <span>$&lt;4k$</span>. See <a href="../MainModule/#Threads-1">Threads</a>.</p></div></div><div class="admonition note"><div class="admonition-title">Nota Bene</div><div class="admonition-text"><p>In normal circumstances this algorithm converges monothonically. If the algorithm diverges and <code>â°</code> is true a <strong>warning</strong> is printed indicating the iteration when this happened.</p><p>The exponential decaying step size features a faster convergence rate as compared to the fixed step size <span>$Ï‚=1$</span> that is usually adopted. The decaying rate is inversely proportional to <code>maxiter</code>, thus, increase/decrease <code>maxiter</code> in order to set a slower/faster decaying rate. <code>maxiter</code> should not be set too low though.</p><p><span>$tol$</span> defaults to the square root of <code>Base.eps</code> of the nearest real type of data input <span>$ğ$</span>. This corresponds to requiring the norm of the satisfying matrix equation divided by the number of elements to vanish for about half the significant digits.</p></div></div><p><strong>See</strong>: <a href="../introToRiemannianGeometry/#Fisher-1">Fisher</a> metric.</p><p><strong>See also</strong>: <a href="#PosDefManifold.geometricpMean"><code>geometricpMean</code></a>, <a href="#PosDefManifold.powerMean"><code>powerMean</code></a>,  <a href="#PosDefManifold.wasMean"><code>wasMean</code></a>, <a href="#PosDefManifold.logdet0Mean"><code>logdet0Mean</code></a>, <a href="#Statistics.mean"><code>mean</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using LinearAlgebra, PosDefManifold
# Generate a set of 4 random 3x3 SPD matrices
Pset=randP(3, 4) # or, using unicode: ğ=randP(3, 4)

# unweighted mean
G, iter, conv = geometricMean(Pset) # or G, iter, conv = geometricMean(ğ)

# weights vector, does not need to be normalized
weights=[1, 2, 3, 1]

# weighted mean
G, iter, conv = geometricMean(Pset, w=weights)

# print the convergence at all iterations
G, iter, conv = geometricMean(Pset; â°=true)

# now suppose Pset has changed a bit, initialize with G to hasten convergence
Pset[1]=â„(Pset[1]+(randP(3)/100))
G, iter, conv = geometricMean(Pset; w=weights, âœ“w=true, â°=true, init=G)

# run multi-threaded when the number of matrices is high
using BenchmarkTools
Pset=randP(20, 120)
@benchmark(geometricMean(Pset)) # single-threaded
@benchmark(geometricMean(Pset; â©=true)) # multi-threaded

# show the mean and the input points using spectral embedding
using Plots
k=80
Pset=randP(20, k)
G, iter, conv = geometricMean(Pset; â©=true)
push!(Pset, G)
Î›, U, iter, conv=spectralEmbedding(Fisher, Pset, 2; â°=true)
plot(U[1:k, 1], U[1:k, 2], seriestype=:scatter, title=&quot;Spectral Embedding&quot;, label=&quot;Pset&quot;)
plot!(U[k+1:k+1, 1], U[k+1:k+1, 2], seriestype=:scatter, label=&quot;mean&quot;)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L1491-L1609">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.geometricpMean" href="#PosDefManifold.geometricpMean"><code>PosDefManifold.geometricpMean</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">    geometricpMean(ğ::â„Vector, p::Real=0.5;
    &lt;
    w::Vector=[],
    âœ“w=true,
    init=nothing,
    tol::Real=0,
    maxiter::Int=500,
    adaptStepSize=true,
    â°=false,
    â©=false &gt;)</code></pre><p><strong>alias</strong>: <code>gpmean</code></p><p>Given a 1d array <span>$ğ={P_1,...,P_k}$</span> of <span>$k$</span> positive definite matrices of  <a href="../MainModule/#â„Vector-type-1">â„Vector type</a>, a real parameter <span>$0&lt;p&lt;=1$</span> and optional non-negative real  weights vector <span>$w={w_1,...,w_k}$</span>, return the 3-tuple <span>$(G, iter, conv)$</span>,  where <span>$G$</span> is the <em>p-mean</em>, i.e., the mean according to the  <a href="../introToRiemannianGeometry/#Fisher-1">Fisher</a> metric minimizing the <em>p-dispersion</em> (see below) and  <span>$iter$</span>, <span>$conv$</span> are the number of  iterations and convergence attained by the algorithm.</p><p>This function implements the p-dispersion gradient descent  algorithm with step-size <span>$Ï‚$</span> (to be published), yielding iterations</p><p><span>$G â†G^{1/2}\textrm{exp}\big(Ï‚\sum_{i=1}^{k}pÎ´^2(G, P_i)^{p-1}w_i\textrm{log}(G^{-1/2} P_i G^{-1/2})\big)G^{1/2}.$</span></p><ul><li>if <span>$p=1$</span> this yields the geometric mean (implemented specifically in <a href="#PosDefManifold.geometricMean"><code>geometricMean</code></a>).</li><li>if <span>$p=0.5$</span> this yields the geometric median (default).</li></ul><p>If you don&#39;t pass a weight vector with <em>&lt;optional keyword argument&gt;</em> <span>$w$</span>,  return the <em>unweighted geometric-p mean</em>.</p><p>If <em>&lt;optional keyword argument&gt;</em> <code>âœ“w=true</code> (default), the weights are  normalized so as to sum up to 1, otherwise they are used as they are passed  and should be already normalized.  This option is provided to allow  calling this function repeatedly without normalizing the same weights  vector each time.</p><p>The following are more <em>&lt;optional keyword arguments</em>&gt;:</p><ul><li><code>init</code> is a matrix to be used as initialization for the mean. If no matrix is provided, the <a href="../introToRiemannianGeometry/#log-Euclidean-1">log Euclidean</a> mean will be used,</li><li><code>tol</code> is the tolerance for the convergence (see below).</li><li><code>maxiter</code> is the maximum number of iterations allowed.</li><li>if <code>adaptStepSize</code>=true (default) the step size <span>$Ï‚$</span> for the gradient descent is adapted at each iteration (see below).</li><li>if <code>â°</code>=true, the step-size and convergence attained at each iteration is printed. Also, a <em>warning</em> is printed if convergence is not attained.</li><li>if â©=true the iterations are multi-threaded (see below).</li></ul><div class="admonition warning"><div class="admonition-title">Multi-Threading</div><div class="admonition-text"><p><a href="https://docs.julialang.org/en/v1/manual/parallel-computing/#Multi-Threading-(Experimental)-1">Multi-threading</a> is still experimental in julia. Multi-threading is automatically disabled if the number of threads Julia is instructed to use is <span>$&lt;2$</span> or <span>$&lt;4k$</span>. See <a href="../MainModule/#Threads-1">Threads</a>.</p></div></div><div class="admonition note"><div class="admonition-title">Nota Bene</div><div class="admonition-text"><p>If the algorithm diverges and <code>â°</code> is true a <strong>warning</strong> is printed indicating the iteration when this happened. This algorithm may temporary diverge, still reach convergence. Overall, while all other iterative algorithms implemented in <strong>PosDefMaifold</strong> are very stable, this is not.</p><p>The smaller the parameter <span>$p$</span> is, the slower and less likely the convergence is. If the algorithm does not converge, try increasing <span>$p$</span>, initializing the algorithm with the output of <a href="#PosDefManifold.geometricMean"><code>geometricMean</code></a> and/or eliminating the otliers from the input set <span>$ğ$</span>.</p><p>If <code>adaptStepSize</code> is true (default) the step-size <span>$Ï‚$</span> is adapted at each iteration, otherwise a fixed step size <span>$Ï‚=1$</span> is used. Adapting the step size in general hastens convergence and improves the convergence behavior.</p><p><span>$tol$</span> defaults to the square root of <code>Base.eps</code> of the nearest real type of data input <span>$ğ$</span>. This corresponds to requiring the norm of the satisfying matrix equation divided by the number of elements to vanish for about half the significant digits.</p></div></div><p><strong>See</strong>: <a href="../introToRiemannianGeometry/#Fisher-1">Fisher</a> metric.</p><p><strong>See also</strong>: <a href="#PosDefManifold.geometricMean"><code>geometricMean</code></a>, <a href="#PosDefManifold.powerMean"><code>powerMean</code></a>,  <a href="#PosDefManifold.wasMean"><code>wasMean</code></a>, <a href="#PosDefManifold.logdet0Mean"><code>logdet0Mean</code></a>, <a href="#Statistics.mean"><code>mean</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using LinearAlgebra, PosDefManifold, Plots

# This examples show that this algorithm is more robust to outliers
# as compared to the standard geometric mean algorithm

# Generate a set of 100 random 10x10 SPD matrices
Pset=randP(10, 100)

# Get the usual geometric mean for comparison
G, iter1, conv1 = geometricMean(Pset, â°=true, â©=true)

# change p to observe how the convergence behavior changes accordingly
# Get the median (default)
H, iter2, conv2 = geometricpMean(Pset, â°=true, â©=true)
# Get the p-mean for p=0.25
H, iter2, conv2 = geometricpMean(Pset, 0.25, â°=true, â©=true)

println(iter1, &quot; &quot;, iter2); println(conv1, &quot; &quot;, conv2)

# move the first matrix in Pset to possibly create an otlier
Pset[1]=geodesic(Fisher, G, Pset[1], 3)
G1, iter1, conv1 = geometricMean(Pset, â°=true, â©=true)
H1, iter2, conv2 = geometricpMean(Pset, 0.25, â°=true, â©=true)
println(iter1, &quot; &quot;, iter2); println(conv1, &quot; &quot;, conv2)

# collect the geometric and p-means, before and after the
# introduction of the outier in vector of Hermitian matrices `S`.
S=HermitianVector([G, G1, H, H1])

# check the interdistance matrix Î”Â² to verify that the geometric mean
# after the introduction of the outlier (``G1``) is farther away from
# the geometric mean as compared to how much ``H1`` is further away
# from ``H``, i.e., that element (4,3) is much smaller than element (2,1).
Î”Â²=distanceÂ²Mat(Float64, Fisher, S)

# how far are all these matrices from all the others?
fullÎ”Â²=Hermitian(Î”Â², :L)
dist=[sum(fullÎ”Â²[:, i]) for i=1:size(fullÎ”Â², 1)]

# plot the matrices in `S` using spectral embedding.
using Plots
Î›, U, iter, conv = laplacianEM(laplacian(Î”Â²), 3;  â°=true)
plot([U[1, 1]], [U[1, 2]], seriestype=:scatter, label=&quot;g-mean&quot;)
plot!([U[2, 1]], [U[2, 2]], seriestype=:scatter, label=&quot;g-mean outlier&quot;)
plot!([U[3, 1]], [U[3, 2]], seriestype=:scatter, label=&quot;p-mean&quot;)
plot!([U[4, 1]], [U[4, 2]], seriestype=:scatter, label=&quot;p-mean outlier&quot;)

# estimate how much you gain running the algorithm in multi-threaded mode
using BenchmarkTools
Pset=randP(20, 120)
@benchmark(geometricpMean(Pset)) # single-threaded
@benchmark(geometricpMean(Pset; â©=true)) # multi-threaded</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L1665-L1800">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.logdet0Mean" href="#PosDefManifold.logdet0Mean"><code>PosDefManifold.logdet0Mean</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">    logdet0Mean(ğ::Union{â„Vector, ğ”»Vector};
    &lt;
    w::Vector=[],
    âœ“w=true,
    init=nothing,
    tol::Real=0,
    maxiter::Int=500,
    â°=false,
    â©=false &gt;)</code></pre><p><strong>alias</strong>: <code>ld0Mean</code></p><p>Given a 1d array <span>$ğ={P_1,...,P_k}$</span> of <span>$k$</span> positive definite matrices of  <a href="../MainModule/#â„Vector-type-1">â„Vector type</a> or real positive definite diagonal matrices of  <a href="../MainModule/#ğ”»Vector-type-1">ğ”»Vector type</a> and optional  non-negative real weights vector <span>$w={w_1,...,w_k}$</span>,  return the 3-tuple <span>$(G, iter, conv)$</span>, where <span>$G$</span> is the mean according  to the <a href="../introToRiemannianGeometry/#logdet-zero-1">logdet zero</a> metric and <span>$iter$</span>, <span>$conv$</span> are the number of iterations  and convergence attained by the algorithm.  Mean <span>$G$</span> is the unique positive definite matrix satisfying</p><p><span>$\sum_{i=1}^{k}w_i\big(\frac{1}{2}P_i+\frac{1}{2}G\big)^{-1}-G^{-1}=0$</span>.</p><p>For estimating it, this function implements the fixed-point iteration algorithm  suggested by (Moakher, 2012, p315)<a href="../introToRiemannianGeometry/#-1">ğŸ“</a>, yielding iterations</p><p><span>$G â† \frac{1}{2}\big(\sum_{i=1}^{k}w_i(P_i+G)^{-1}\big)^{-1}$</span>.</p><p>If you don&#39;t pass a weight vector with <em>&lt;optional keyword argument&gt;</em> <span>$w$</span>,  return the <em>unweighted logdet zero mean</em>.</p><p>If <em>&lt;optional keyword argument&gt;</em> <code>âœ“w=true</code> (default), the weights are  normalized so as to sum up to 1, otherwise they are used as they are passed  and should be already normalized.  This option is provided to allow  calling this function repeatedly without normalizing the same weights  vector each time.</p><p>The following are more <em>&lt;optional keyword arguments</em>&gt;:</p><ul><li><code>init</code> is a matrix to be used as initialization for the mean. If no matrix is provided, the <a href="../introToRiemannianGeometry/#log-Euclidean-1">log Euclidean</a> mean will be used,</li><li><code>tol</code> is the tolerance for the convergence (see below).</li><li><code>maxiter</code> is the maximum number of iterations allowed.</li><li>if <code>â°</code>=true, the convergence attained at each iteration is printed and a <em>warning</em> is printed if convergence is not attained.</li><li>if â©=true the iterations are multi-threaded (see below).</li></ul><div class="admonition warning"><div class="admonition-title">Multi-Threading</div><div class="admonition-text"><p><a href="https://docs.julialang.org/en/v1/manual/parallel-computing/#Multi-Threading-(Experimental)-1">Multi-threading</a> is still experimental in julia. Multi-threading is automatically disabled if the number of threads Julia is instructed to use is <span>$&lt;2$</span> or <span>$&lt;4k$</span>. See <a href="../MainModule/#Threads-1">Threads</a>.</p></div></div><div class="admonition note"><div class="admonition-title">Nota Bene</div><div class="admonition-text"><p>In normal circumstances this algorithm converges monothonically. If the algorithm diverges and <code>â°</code> is true a <strong>warning</strong> is printed indicating the iteration when this happened.</p><p><span>$tol$</span> defaults to 100 times the square root of <code>Base.eps</code> of the nearest real type of data input <span>$ğ$</span>. This corresponds to requiring the square root of the relative convergence criterion over two successive iterations to vanish for about half the significant digits minus 2.</p></div></div><p><strong>See</strong>: <a href="../introToRiemannianGeometry/#logdet-zero-1">logdet zero</a> metric, <a href="../introToRiemannianGeometry/#modified-Bhattacharyya-mean-1">modified Bhattacharyya mean</a>.</p><p><strong>See also</strong>: <a href="#PosDefManifold.powerMean"><code>powerMean</code></a>, <a href="#PosDefManifold.wasMean"><code>wasMean</code></a>, <a href="#PosDefManifold.logdet0Mean"><code>logdet0Mean</code></a>,  <a href="#Statistics.mean"><code>mean</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using LinearAlgebra, PosDefManifold
# Generate a set of 4 random 3x3 SPD matrices
Pset=randP(3, 4) # or, using unicode: ğ=randP(3, 4)

# unweighted mean
G, iter, conv = logdet0Mean(Pset) # or G, iter, conv = logdet0Mean(ğ)

# weights vector, does not need to be normalized
weights=[1, 2, 3, 1]

# weighted mean
G, iter, conv = logdet0Mean(Pset, w=weights)

# print the convergence at all iterations
G, iter, conv = logdet0Mean(Pset; w=weights, â°=true)

# suppose Pset has changed a bit; initialize with G to hasten convergence
Pset[1]=â„(Pset[1]+(randP(3)/100))
G, iter, conv = logdet0Mean(Pset; w=weights, âœ“w=false, â°=true, init=G)

# estimate how much you gain running the algorithm in multi-threaded mode
using BenchmarkTools
Pset=randP(20, 120)
@benchmark(logdet0Mean(Pset)) # single-threaded
@benchmark(logdet0Mean(Pset; â©=true)) # multi-threaded</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L1871-L1966">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.wasMean" href="#PosDefManifold.wasMean"><code>PosDefManifold.wasMean</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">    wasMean(ğ::Union{â„Vector, ğ”»Vector};
    &lt;
    w::Vector=[],
    âœ“w=true,
    init=nothing,
    tol::Real=0,
    maxiter::Int=500,
    â°=false,
    â©=false &gt;)</code></pre><p>Given a 1d array <span>$ğ={P_1,...,P_k}$</span> of <span>$k$</span> positive definite matrices  of <a href="../MainModule/#â„Vector-type-1">â„Vector type</a> or real positive definite diagonal matrices of  <a href="../MainModule/#ğ”»Vector-type-1">ğ”»Vector type</a> and optional non-negative real weights vector  <span>$w={w_1,...,w_k}$</span>,  return the 3-tuple <span>$(G, iter, conv)$</span>, where <span>$G$</span> is the mean according  to the <a href="../introToRiemannianGeometry/#Wasserstein-1">Wasserstein</a> metric and <span>$iter$</span>, <span>$conv$</span> are the number of iterations  and convergence attained by the algorithm.  Mean <span>$G$</span> is the unique positive definite matrix satisfying</p><p><span>$G=\sum_{i=1}^{k}w_i\big( G^{1/2}  P_i G^{1/2}\big)^{1/2}$</span>.</p><p>For estimating it, this function implements the fixed-point iterative algorithm  proposed by (Ãlvarez-Esteban et <em>al.</em>, 2016)<a href="../introToRiemannianGeometry/#-1">ğŸ“</a>:</p><p><span>$G â† G^{-1/2}\big(\sum_{i=1}^{k} w_i(G^{1/2}P_i G^{1/2})^{1/2}\big)^2 G^{-1/2}$</span>.</p><p>If you don&#39;t pass a weight vector with <em>&lt;optional keyword argument&gt;</em> <span>$w$</span>,  return the <em>unweighted Wassertein mean</em>.</p><p>If <em>&lt;optional keyword argument&gt;</em> <code>âœ“w=true</code> (default), the weights are  normalized so as to sum up to 1, otherwise they are used as they are passed  and they should be already normalized.  This option is provided to allow  calling this function repeatedly without normalizing the same weights  vector each time.</p><p>The following are more <em>&lt;optional keyword arguments</em>&gt;:</p><ul><li><code>init</code> is a matrix to be used as initialization for the mean. If no matrix is provided, the instance of <a href="../introToRiemannianGeometry/#generalized-means-1">generalized means</a> with <span>$p=0.5$</span> will be used,</li><li><code>tol</code> is the tolerance for the convergence (see below).</li><li><code>maxiter</code> is the maximum number of iterations allowed.</li><li>if <code>â°</code>=true, the convergence attained at each iteration is printed and a <em>warning</em> is printed if convergence is not attained.</li><li>if â©=true the iterations are multi-threaded (see below).</li></ul><p>If the input is a 1d array of <span>$k$</span> real positive definite diagonal matrices  the solution is available in closed-form as the modified Bhattacharyya mean,  hence the <em>&lt;optional keyword arguments</em>&gt; <code>init</code>, <code>tol</code> and <code>â°</code>  have no effect and return the 3-tuple <span>$(G, 1, 0)$</span>.  See <a href="../introToRiemannianGeometry/#modified-Bhattacharyya-mean-1">modified Bhattacharyya mean</a>.</p><div class="admonition warning"><div class="admonition-title">Multi-Threading</div><div class="admonition-text"><p><a href="https://docs.julialang.org/en/v1/manual/parallel-computing/#Multi-Threading-(Experimental)-1">Multi-threading</a> is still experimental in julia. Multi-threading is automatically disabled if the number of threads Julia is instructed to use is <span>$&lt;2$</span> or <span>$&lt;4k$</span>. See <a href="../MainModule/#Threads-1">Threads</a>.</p></div></div><div class="admonition note"><div class="admonition-title">Nota Bene</div><div class="admonition-text"><p>In normal circumstances this algorithm converges monothonically. If the algorithm diverges and <code>â°</code> is true a <strong>warning</strong> is printed indicating the iteration when this happened.</p><p><span>$tol$</span> defaults to the square root of <code>Base.eps</code> of the nearest real type of data input <span>$ğ$</span>. This corresponds to requiring the norm of the satisfying matrix equation divided by the number of elements to vanish for about half the significant digits.</p></div></div><p><strong>See</strong>: <a href="../introToRiemannianGeometry/#Wasserstein-1">Wasserstein</a> metric.</p><p><strong>See also</strong>: <a href="#PosDefManifold.powerMean"><code>powerMean</code></a>, <a href="#PosDefManifold.wasMean"><code>wasMean</code></a>, <a href="#PosDefManifold.logdet0Mean"><code>logdet0Mean</code></a>,  <a href="#Statistics.mean"><code>mean</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using LinearAlgebra, PosDefManifold
# Generate a set of 4 random 3x3 SPD matrices
Pset=randP(3, 4) # or, using unicode: ğ=randP(3, 4)

# unweighted mean
G, iter, conv = wasMean(Pset) # or: G, iter, conv = wasMean(ğ)

# weights vector, does not need to be normalized
weights=[1, 2, 3, 1]

# weighted mean
G, iter, conv = wasMean(Pset; w=weights)

# print the convergence at all iterations
G, iter, conv = wasMean(Pset; w=weights, â°=true)

# suppose ğ has changed a bit; initialize with G to hasten convergence
Pset[1]=â„(Pset[1]+(randP(3)/100))
G, iter, conv = wasMean(Pset; w=weights, â°=true, init=G)

# estimate how much you gain running the algorithm in multi-threaded mode
using BenchmarkTools
Pset=randP(20, 120)
@benchmark(wasMean(Pset)) # single-threaded
@benchmark(wasMean(Pset; â©=true)) # multi-threaded</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L2017-L2116">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.powerMean" href="#PosDefManifold.powerMean"><code>PosDefManifold.powerMean</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">    powerMean(ğ::Union{â„Vector, ğ”»Vector}, p::Real;
    &lt;
    w::Vector=[],
    âœ“w=true,
    init=nothing,
    tol::Real=0,
    maxiter::Int=500,
    â°=false,
    â©=false &gt;)</code></pre><p>Given a 1d array <span>$ğ={P_1,...,P_k}$</span> of <span>$k$</span> positive definite matrices  of <a href="../MainModule/#â„Vector-type-1">â„Vector type</a> or real positive definite diagonal matrices of  <a href="../MainModule/#ğ”»Vector-type-1">ğ”»Vector type</a>, an optional non-negative real weights vector  <span>$w={w_1,...,w_k}$</span> and a real parameter <code>p</code> <span>$\in[-1, 1]$</span>, return the  3-tuple <span>$(G, iter, conv)$</span>, where <span>$G$</span> is  Lim and Palfia (2012)&#39;s <a href="../introToRiemannianGeometry/#power-means-1">power means</a>  of order <span>$p$</span> and  <span>$iter$</span>, <span>$conv$</span> are the number of iterations  and convergence attained by the algorithm, respectively.  Mean <span>$G$</span> is the unique positive definite matrix satisfying</p><p><span>$G=\sum_{i=1}^{k}(w_iG\textrm{#}_pP_i)$</span>,</p><p>where <span>$G\textrm{#}_pP_i$</span> is the <a href="../introToRiemannianGeometry/#Fisher-1">Fisher</a> <a href="../introToRiemannianGeometry/#geodesic-1">geodesic</a> equation.  In particular:</p><ul><li>with <span>$p=-1$</span> this is the <em>harmonic mean</em> (see the <a href="../introToRiemannianGeometry/#inverse-Euclidean-1">inverse Euclidean</a> metric),</li><li>with <span>$p=+1$</span> this is the <em>arithmetic mean</em> (see the <a href="../introToRiemannianGeometry/#Euclidean-1">Euclidean</a> metric),</li><li>at the limit of <span>$p$</span> evaluated at zero from both side this is the <em>geometric mean</em> (see <a href="../introToRiemannianGeometry/#Fisher-1">Fisher</a> metric).</li></ul><p>For estimating power means for <span>$p\in(-1, 1)$</span>, this function implements  the  fixed-point iterative algorithm of (Congedo et <em>al.</em>, 2017b)<a href="../introToRiemannianGeometry/#-1">ğŸ“</a>.  For <span>$p=0$</span> (geometric mean)  this algorithm is run two times with a small positive and negative value  of <span>$p$</span> and the geometric mean of the two  resulting means is returned, as suggested in (Congedo et <em>al.</em>, 2017b)<a href="../introToRiemannianGeometry/#-1">ğŸ“</a>.  This way of estimating the geometric mean of  a set of matrices is faster as compared to the usual gradient descent algorithm.</p><p>If you don&#39;t pass a weight vector with <em>&lt;optional keyword argument&gt;</em> <span>$w$</span>,  return the <em>unweighted power mean</em>.</p><p>If <em>&lt;optional keyword argument&gt;</em> <code>âœ“w=true</code> (default), the weights are  normalized so as to sum up to 1, otherwise they are used as they are passed  and should be already normalized.  This option is provided to allow  calling this function repeatedly without normalizing the same weights  vector each time.</p><p>The following are more <em>&lt;optional keyword arguments</em>&gt;:</p><ul><li><code>init</code> is a matrix to be used as initialization for the mean. If no matrix is provided, the instance of <a href="../introToRiemannianGeometry/#generalized-means-1">generalized means</a> with parameter <span>$p$</span> will be used.</li><li><code>tol</code> is the tolerance for the convergence (see below).</li><li><code>maxiter</code> is the maximum number of iterations allowed.</li><li>if <code>â°</code>=true, the convergence attained at each iteration is printed and a <em>warning</em> is printed if convergence is not attained.</li><li>if â©=true the iterations are multi-threaded.</li></ul><p>If the input is a 1d array of <span>$k$</span> real positive definite diagonal matrices  the solution is available in closed-form as the generalized  mean of order <code>p</code>, hence the <em>&lt;optional keyword arguments</em>&gt;  <code>init</code>, <code>tol</code> and <code>â°</code>  have no effect and return the 3-tuple <span>$(G, 1, 0)$</span>.  See <a href="../introToRiemannianGeometry/#generalized-means-1">generalized means</a>.</p><div class="admonition warning"><div class="admonition-title">Multi-Threading</div><div class="admonition-text"><p><a href="https://docs.julialang.org/en/v1/manual/parallel-computing/#Multi-Threading-(Experimental)-1">Multi-threading</a> is still experimental in julia. Multi-threading is automatically disabled if the number of threads Julia is instructed to use is <span>$&lt;2$</span> or <span>$&lt;4k$</span>. See <a href="../MainModule/#Threads-1">Threads</a>.</p></div></div><div class="admonition note"><div class="admonition-title">Nota Bene</div><div class="admonition-text"><p>In normal circumstances this algorithm converges monothonically. If the algorithm diverges and <code>â°</code> is true a <strong>warning</strong> is printed indicating the iteration when this happened.</p><p><span>$tol$</span> defaults to the square root of <code>Base.eps</code> of the nearest real type of data input <span>$ğ$</span>. This corresponds to requiring the norm of the difference of the matrix solution over two successive iterations divided by the number of elements in the matrix to vanish for about half the significant digits.</p></div></div><p>(2) Like in (1), but for a 1d array <span>$ğƒ={D_1,...,D_k}$</span> of <span>$k$</span>  real positive definite diagonal matrices of <a href="../MainModule/#ğ”»Vector-type-1">ğ”»Vector type</a>.  In this case the solution is available in closed-form, hence the  <em>&lt;optional keyword arguments</em>&gt; <code>init</code>, <code>tol</code> and <code>â°</code> have no effect and return  the 3-tuple <span>$(G, 1, 0)$</span>. See <a href="../introToRiemannianGeometry/#generalized-means-1">generalized means</a>.</p><p><strong>See</strong>: <a href="../introToRiemannianGeometry/#power-means-1">power means</a>, <a href="../introToRiemannianGeometry/#generalized-means-1">generalized means</a>, <a href="../introToRiemannianGeometry/#modified-Bhattacharyya-mean-1">modified Bhattacharyya mean</a>.</p><p><strong>See also</strong>: <a href="#PosDefManifold.generalizedMean"><code>generalizedMean</code></a>, <a href="#PosDefManifold.wasMean"><code>wasMean</code></a>, <a href="#PosDefManifold.logdet0Mean"><code>logdet0Mean</code></a>,  <a href="#Statistics.mean"><code>mean</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using LinearAlgebra, PosDefManifold
# Generate a set of 4 random 3x3 SPD matrices
Pset=randP(3, 4) # or, using unicode: ğ=randP(3, 4)

# unweighted mean
G, iter, conv = powerMean(Pset, 0.5) # or G, iter, conv = powerMean(ğ, 0.5)

# weights vector, does not need to be normalized
weights=[1, 2, 3, 1]

# weighted mean
G, iter, conv = powerMean(Pset, 0.5; w=weights)

# print the convergence at all iterations
G, iter, conv = powerMean(Pset, 0.5; w=weights, â°=true)

# suppose ğ has changed a bit; initialize with G to hasten convergence
Pset[1]=â„(Pset[1]+(randP(3)/100))
G, iter, conv = powerMean(Pset, 0.5; w=weights, â°=true, init=G)

# estimate how much you gain running the algorithm in multi-threaded mode
using BenchmarkTools
Pset=randP(20, 120)
@benchmark(powerMean(Pset, 0.5)) # single-threaded
@benchmark(powerMean(Pset, 0.5; â©=true)) # multi-threaded</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L2170-L2289">source</a></section><h2><a class="nav-anchor" id="Tangent-Space-operations-1" href="#Tangent-Space-operations-1">Tangent Space operations</a></h2><table><tr><th>Function</th><th>Description</th></tr><tr><td><a href="#PosDefManifold.logMap"><code>logMap</code></a></td><td>Logarithmic map (from manifold to tangent space)</td></tr><tr><td><a href="#PosDefManifold.expMap"><code>expMap</code></a></td><td>Exponential map (from tangent space to manifold)</td></tr><tr><td><a href="#PosDefManifold.vecP"><code>vecP</code></a></td><td>vectorization of matrices in the tangent space</td></tr><tr><td><a href="#PosDefManifold.matP"><code>matP</code></a></td><td>matrization of matrices in the tangent space (inverse of <code>vecp</code>)</td></tr><tr><td><a href="#PosDefManifold.parallelTransport"><code>parallelTransport</code></a>, pt</td><td>Parallel transport of tangent vectors and matrices</td></tr></table><p>â‹…</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.logMap" href="#PosDefManifold.logMap"><code>PosDefManifold.logMap</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">(1) logMap(metric::Metric, P::â„{T}, G::â„{T})

(2) logMap(metric::Metric, ğ::â„Vector, G::â„{T})
for all the above: where T&lt;:RealOrComplex</code></pre><p>(1) <em>Logaritmic Map:</em> map a positive definite matrix <span>$P$</span> from the SPD or  Hermitian manifold into the tangent space at base-point <span>$G$</span> using the <a href="../introToRiemannianGeometry/#Fisher-1">Fisher</a> metric.</p><p><span>$P$</span> and <span>$G$</span> must be flagged as <code>Hermitian</code>. See <a href="../MainModule/#typecasting-matrices-1">typecasting matrices</a>.</p><p>The map is defined as</p><p><span>$Log_G(P)=S=G^{1/2}\textrm{log}\big(G^{-1/2}PG^{-1/2}\big)G^{1/2}$</span>.</p><p><code>metric</code> is a metric of type <a href="../MainModule/#Metric::Enumerated-type-1">Metric::Enumerated type</a>.</p><p>The result is an <code>Hermitian</code> matrix.</p><p>(2) <em>Logarithmic map</em> (1) at base-point <span>$G$</span> at once for <span>$k$</span> positive definite  matrices in 1d array <span>$ğ={P_1,...,P_k}$</span> of <a href="../MainModule/#â„Vector-type-1">â„Vector type</a>.</p><p>The result is an <code>â„Vector</code>.</p><div class="admonition note"><div class="admonition-title">Nota Bene</div><div class="admonition-text"><p>Currently only the <a href="../introToRiemannianGeometry/#Fisher-1">Fisher</a> metric is supported for tangent space operations.</p></div></div><p>The inverse operation is <a href="#PosDefManifold.expMap"><code>expMap</code></a>.</p><p><strong>See also</strong>: <a href="#PosDefManifold.vecP"><code>vecP</code></a>, <a href="#PosDefManifold.parallelTransport"><code>parallelTransport</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using PosDefManifold
(1)
P=randP(3)
Q=randP(3)
metric=Fisher
G=mean(metric, P, Q)
# projecting P at the base point given by the geometric mean of P and Q
S=logMap(metric, P, G)

(2)
Pset=randP(3, 4)
# projecting all matrices in Pset at the base point given by their geometric mean.
Sset=logMap(Fisher, Pset, mean(Fisher, Pset))</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L2373-L2419">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.expMap" href="#PosDefManifold.expMap"><code>PosDefManifold.expMap</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">(1) expMap(metric::Metric, S::â„{T}, G::â„{T})

(2) expMap(metric::Metric, ğ’::â„Vector, G::â„{T})
for all the above: where T&lt;:RealOrComplex</code></pre><p>(1) <em>Exponential Map:</em> map a tangent vector (a matrix) <span>$S$</span> from the tangent  space at base-point <span>$G$</span> into the SPD or Hermitian manifold  (using the <a href="../introToRiemannianGeometry/#Fisher-1">Fisher</a> metric).</p><p><span>$S$</span> and <span>$G$</span> must be flagged as <code>Hermitian</code>. See <a href="../MainModule/#typecasting-matrices-1">typecasting matrices</a>.</p><p>The map is defined as</p><p><span>$Exp_G(S)=P=G^{1/2}\textrm{exp}\big(G^{-1/2}SG^{-1/2}\big)G^{1/2}$</span>.</p><p><code>metric</code> is a metric of type <a href="../MainModule/#Metric::Enumerated-type-1">Metric::Enumerated type</a>.</p><p>The result is an <code>Hermitian</code> matrix.</p><p>(2) <em>Exponential map</em> (1) at base-point <span>$G$</span> at once for <span>$k$</span> tangent vectors  (matrices) in 1d array <span>$ğ’={S_1,...,S_k}$</span> of <a href="../MainModule/#â„Vector-type-1">â„Vector type</a>.</p><p>The result is an <code>â„Vector</code>.</p><div class="admonition note"><div class="admonition-title">Nota Bene</div><div class="admonition-text"><p>Currently only the <a href="../introToRiemannianGeometry/#Fisher-1">Fisher</a> metric is supported for tangent space operations.</p></div></div><p>The inverse operation is <a href="#PosDefManifold.logMap"><code>logMap</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">(1)
using PosDefManifold, LinearAlgebra
P=randP(3)
Q=randP(3)
G=mean(Fisher, P, Q)
# projecting P on the tangent space at the Fisher mean base point G
S=logMap(Fisher, P, G)
# projecting back onto the manifold
P2=expMap(Fisher, S, G)

(2)
Pset=randP(3, 4)
# projecting all matrices in Pset at the base point given by their geometric mean.
G=mean(Fisher, Pset)
Sset=logMap(Fisher, Pset, G)
# projecting back onto the manifold
Pset2=expMap(Fisher, Sset, G)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L2438-L2488">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.vecP" href="#PosDefManifold.vecP"><code>PosDefManifold.vecP</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">vecP(S::â„{T}) where T&lt;:RealOrComplex</code></pre><p><em>Vectorize</em> a tangent vector (which is an <code>Hermitian</code> matrix) <span>$S$</span>:  mat -&gt; vec.</p><p>It gives weight <span>$1$</span> to diagonal elements and âˆš2 to off-diagonal elements  (Barachant et <em>al.</em>, 2012)<a href="../introToRiemannianGeometry/#-1">ğŸ“</a>.</p><p>The result is a vector holding <span>$n(n+1)/2$</span> elements, where <span>$n$</span>  is the size of <span>$S$</span>.</p><p><span>$S$</span> must be flagged as Hermitian. See <a href="../MainModule/#typecasting-matrices-1">typecasting matrices</a>.</p><p>The inverse operation is provided by <a href="#PosDefManifold.matP"><code>matP</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using PosDefManifold
P=randP(3)
Q=randP(3)
G=mean(Fisher, P, Q)
# projecting P at the base point given by the geometric mean of P and Q
S=logMap(Fisher, P, G)
# vectorize S
v=vecP(S)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L2507-L2531">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.matP" href="#PosDefManifold.matP"><code>PosDefManifold.matP</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">matP(Ï‚::Vector{T}) where T&lt;:RealOrComplex</code></pre><p><em>Matrizize</em> a tangent vector (vector) Ï‚ :  vec -&gt; mat.</p><p>This is the function reversing the <a href="#PosDefManifold.vecP"><code>vecP</code></a> function,  thus the weighting applied therein is reversed as well.</p><p>If <span>$Ï‚=vecP(S)$</span> and <span>$S$</span> is a <span>$nâ‹…n$</span> Hermitian matrix,  <span>$Ï‚$</span>  is a tangent vector of size <span>$n(n+1)/2$</span>.  The result of calling <code>matP(Ï‚)</code> is then <span>$nâ‹…n$</span> matrix <span>$S$</span>.</p><p><strong>To Do</strong>: This function needs to be rewritten more efficiently.</p><p><strong>Examples</strong></p><pre><code class="language-none">using PosDefManifold
P=randP(3)
Q=randP(3)
G=mean(Fishr, P, Q)
# projecting P at onto the tangent space at the Fisher mean base point
S=logMap(Fisher, P, G)
# vectorize S
v=vecP(S)
# Rotate the vector by an orthogonal matrix
n=Int(size(S, 1)*(size(S, 1)+1)/2)
U=randP(n)
z=U*v
# Get the point in the tangent space
S=matP(z)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L2536-L2565">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.parallelTransport" href="#PosDefManifold.parallelTransport"><code>PosDefManifold.parallelTransport</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">(1) parallelTransport(S::â„{T}, P::â„{T}, Q::â„{T})

(2) parallelTransport(S::â„{T}, P::â„{T})

(3) parallelTransport(ğ’::â„Vector, P::â„{T}, Q::â„{T})

(4) parallelTransport(ğ’::â„Vector, P::â„{T})
for all the above: where T&lt;:RealOrComplex</code></pre><p><strong>alias</strong>: <code>pt</code></p><p>(1) <em>Parallel transport</em> of tangent vector <span>$S$</span> (a matrix) lying on the tangent space  at base-point <span>$P$</span> to the tangent space at base-point <span>$Q$</span>.</p><p><span>$S$</span>, <span>$P$</span> and <span>$Q$</span> must all be <code>Hermitian</code> matrices.  Return an <code>Hermitian</code> matrix.  The transport is defined as:</p><p><span>$âˆ¥_{(Pâ†’Q)}(S)=\big(QP^{-1}\big)^{1/2}S\big(QP^{-1}\big)^{H/2}$</span>.</p><p>If <span>$S$</span> is a positive definite matrix in the manifold (and not a tangent vector)  it will be &#39;trasported&#39; from <span>$P$</span> to <span>$Q$</span>, amounting to (Yair et <em>al.</em>, 2019<a href="../introToRiemannianGeometry/#-1">ğŸ“</a>)</p><ul><li>project <span>$S$</span> onto the tangent space at base-point <span>$P$</span>,</li><li>parallel transport it to the tangent space at base-point <span>$Q$</span>,</li><li>project it back onto the manifold at base-point <span>$Q$</span>.</li></ul><p>(2) <em>Parallel transport</em> as in (1), but to the tangent space at base-point the <em>identity matrix</em>.</p><p>The transport reduces in this case to:</p><p><span>$âˆ¥_{(Pâ†’I)}(S)=P^{-1/2}SP^{-1/2}$</span>.</p><p>(3) <em>Parallel transport</em> as in (1) at once for <span>$k$</span> tangent vectors (matrices) in 1d array <span>$ğ’={S_1,...,S_k}$</span> of <a href="../MainModule/#â„Vector-type-1">â„Vector type</a>.</p><p>(4) <em>Parallel transport</em> as in (2) at once for <span>$k$</span> tangent vectors (matrices) in 1d array <span>$ğ’={S_1,...,S_k}$</span> of <a href="../MainModule/#â„Vector-type-1">â„Vector type</a>.</p><div class="admonition note"><div class="admonition-title">Nota Bene</div><div class="admonition-text"><p>Currently only the <a href="../introToRiemannianGeometry/#Fisher-1">Fisher</a> metric is supported for parallel transport.</p></div></div><p><strong>See also</strong>: <a href="#PosDefManifold.logMap"><code>logMap</code></a>, <a href="#PosDefManifold.expMap"><code>expMap</code></a>, <a href="#PosDefManifold.vecP"><code>vecP</code></a>, <a href="#PosDefManifold.matP"><code>matP</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using PosDefManifold

(1)
P=randP(3)
Q=randP(3)
G=mean(Fisher, P, Q)

# i. projecting P onto the tangent space at base-point G
S=logMap(Fisher, P, G)
# ii. parallel transport S to the tangent space at base-point Q
S_=parallelTransport(S, G, Q)
# iii. projecting back into the manifold at base-point Q
P_=expMap(Fisher, S_, Q)

# i., ii. and iii. can be done simply by
PP_=parallelTransport(P, G, Q)
# check
P_â‰ˆPP_ ? println(&quot; â­ &quot;) : println(&quot; â›” &quot;)

(2)
P=randP(3)
Q=randP(3)
G=mean(Fisher, P, Q)
# transport to the tangent space at base-point the identity
PP_=parallelTransport(P, G)

(3)
Pset=randP(3, 4)
Q=randP(3)
G=mean(Fisher, Pset)
# trasport at once all matrices in Pset
Pset2=parallelTransport(Pset, G, Q)

(4)
Pset=randP(3, 4)
G=mean(Fisher, Pset)
# recenter all matrices so to have mean=I
Pset2=parallelTransport(Pset, G)
# check
mean(Fisher, Pset2) â‰ˆ I ? println(&quot; â­ &quot;) : println(&quot; â›” &quot;)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L2583-L2670">source</a></section><h2><a class="nav-anchor" id="Procrustes-problems-1" href="#Procrustes-problems-1">Procrustes problems</a></h2><table><tr><th>Function</th><th>Description</th></tr><tr><td><a href="#PosDefManifold.procrustes"><code>procrustes</code></a></td><td>Solution to the Procrustes problem in the manifold of positive definite matrices</td></tr></table><p>â‹…</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PosDefManifold.procrustes" href="#PosDefManifold.procrustes"><code>PosDefManifold.procrustes</code></a> â€” <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">procrustes(P::â„{T}, Q::â„{T}, extremum=&quot;min&quot;) where T&lt;:RealOrComplex</code></pre><p>Given two positive definite matrices <span>$P$</span> and <span>$Q$</span>,  return by default the solution of problem</p><p><span>$\textrm{argmin}_UÎ´(P,U^HQU)$</span>,</p><p>where <span>$U$</span> varies over the set of unitary matrices and <span>$Î´(.,.)$</span> is a  distance or divergence function.</p><p><span>$U^HQU$</span> is named in physics the <em>unitary orbit</em> of <span>$Q$</span>.</p><p>If the argument <code>extremum</code> is passed as &quot;max&quot;, it returns instead the solution of</p><p><span>$\textrm{argmax}_UÎ´(P,U^HQU)$</span>.</p><p><span>$P$</span> and <span>$Q$</span> must be flagged as <code>Hermitian</code>. See <a href="../MainModule/#typecasting-matrices-1">typecasting matrices</a>.</p><p>As it has been shown in Bhatia and Congedo (2019)<a href="../introToRiemannianGeometry/#-1">ğŸ“</a>,  using each of the <a href="../introToRiemannianGeometry/#Fisher-1">Fisher</a>, <a href="../introToRiemannianGeometry/#logdet-zero-1">logdet zero</a>, <a href="../introToRiemannianGeometry/#Wasserstein-1">Wasserstein</a>  and the Kullback-Leibler divergence (see <a href="../introToRiemannianGeometry/#logdet-Î±-1">logdet Î±</a>),  the best approximant to <span>$P$</span> from the unitary orbit of <span>$Q$</span>  commutes with <span>$P$</span> and, surprisingly, has the same closed-form expression, namely</p><p><span>$U_Q^â†“U_P^{â†“H}$</span> for the argmin and <span>$U_Q^â†‘U_P^{â†“H}$</span> for the argmax,</p><p>where <span>$U^â†“$</span> denotes the eigenvector matrix of the subscript argument with  eigenvectors in columns sorted by <em>decreasing</em> order of corresponding eigenvalues and  <span>$U^â†‘$</span> denotes the eigenvector matrix of the subscript argument with  eigenvectors in columns sorted by <em>increasing</em> order of corresponding eigenvalues.</p><p>The same solutions are known since a long time also by solving the extremal  problem here above using the <a href="../introToRiemannianGeometry/#Euclidean-1">Euclidean</a> metric (Umeyama, 1988).</p><p>The generalized Procrustes problem</p><p><span>$\textrm{argmin}_Usum_{i=1}^{k}Î´(P_i,U^HQ_iU)$</span></p><p>can be solved using Julia package <a href="https://github.com/kellertuer/Manopt.jl">Manopt</a>.</p><p><strong>Examples</strong></p><pre><code class="language-none">using PosDefManifold
P=randP(3)
Q=randP(3)
# argmin problem
U=procrustes(P, Q)
# argmax problem
V=procrustes(P, Q, &quot;max&quot;)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/Marco-Congedo/PosDefManifold.jl/blob/c8abd835d66a924d89dce5be8088abaf99bb44a5/src/riemannianGeometry.jl#L2702-L2751">source</a></section><footer><hr/><a class="previous" href="../MainModule/"><span class="direction">Previous</span><span class="title">MainModule (PosDefManifold.jl)</span></a><a class="next" href="../linearAlgebra/"><span class="direction">Next</span><span class="title">linearAlgebra.jl</span></a></footer></article></body></html>
